<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" lang="en-gb">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Public API &#8212; gptf 1.0.0 documentation</title>
    
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="gptf 1.0.0 documentation" href="index.html" />
    <link rel="prev" title="Welcome to gptf’s documentation!" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="public-api">
<h1>Public API<a class="headerlink" href="#public-api" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="parameterized-classes">
<h2>Parameterized classes<a class="headerlink" href="#parameterized-classes" title="Permalink to this headline">¶</a></h2>
<p>Jump to:</p>
<ul class="simple">
<li><a class="reference internal" href="#gptf.Parameterized" title="gptf.Parameterized"><code class="xref py py-class docutils literal"><span class="pre">gptf.Parameterized</span></code></a></li>
<li><a class="reference internal" href="#gptf.ParamAttributes" title="gptf.ParamAttributes"><code class="xref py py-class docutils literal"><span class="pre">gptf.ParamAttributes</span></code></a></li>
<li><a class="reference internal" href="#gptf.ParamList" title="gptf.ParamList"><code class="xref py py-class docutils literal"><span class="pre">gptf.ParamList</span></code></a></li>
<li><a class="reference internal" href="#gptf.Param" title="gptf.Param"><code class="xref py py-class docutils literal"><span class="pre">gptf.Param</span></code></a></li>
<li><a class="reference internal" href="#gptf.DataHolder" title="gptf.DataHolder"><code class="xref py py-class docutils literal"><span class="pre">gptf.DataHolder</span></code></a></li>
<li><a class="reference internal" href="#gptf.tf_method" title="gptf.tf_method"><code class="xref py py-func docutils literal"><span class="pre">gptf.tf_method()</span></code></a></li>
</ul>
<p>To create a new parameterized class, subclass <a class="reference internal" href="#gptf.Parameterized" title="gptf.Parameterized"><code class="xref py py-class docutils literal"><span class="pre">gptf.Parameterized</span></code></a>
and one of <a class="reference internal" href="#gptf.ParamAttributes" title="gptf.ParamAttributes"><code class="xref py py-class docutils literal"><span class="pre">gptf.ParamAttributes</span></code></a> or <a class="reference internal" href="#gptf.ParamList" title="gptf.ParamList"><code class="xref py py-class docutils literal"><span class="pre">gptf.ParamList</span></code></a>,
depending on how you want parameters to be accessed.</p>
<p>Methods of parameterized objects that create tensorflow objects should
be decorated with <a class="reference internal" href="#gptf.tf_method" title="gptf.tf_method"><code class="xref py py-func docutils literal"><span class="pre">gptf.tf_method()</span></code></a>.</p>
<dl class="class">
<dt id="gptf.Parameterized">
<em class="property">class </em><code class="descclassname">gptf.</code><code class="descname">Parameterized</code><a class="reference internal" href="_modules/gptf/core/params.html#Parameterized"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Parameterized" title="Permalink to this definition">¶</a></dt>
<dd><p>An object that contains parameters and data.</p>
<p>This object is designed to be part of a tree, with <code class="code docutils literal"><span class="pre">Param</span></code>s and
<code class="code docutils literal"><span class="pre">DataHolder</span></code>s at the leaves.</p>
<dl class="attribute">
<dt id="Parameterized.fixed">
<code class="descname">fixed</code><a class="headerlink" href="#Parameterized.fixed" title="Permalink to this definition">¶</a></dt>
<dd><p><em>bool</em> &#8211; A flag indicating whether or not any child <code class="code docutils literal"><span class="pre">Param</span></code>s
should be fixed. Setting this attribute also sets the <code class="code docutils literal"><span class="pre">.fixed</span></code>
attribute of anything lower in the tree.</p>
</dd></dl>

<dl class="attribute">
<dt id="Parameterized.feed_dict">
<code class="descname">feed_dict</code><a class="headerlink" href="#Parameterized.feed_dict" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Dict[tf.placeholder, np.array_like]</em> &#8211; A feed dictionary
that feeds the values of DataHolders into their placeholder ops.</p>
</dd></dl>

<dl class="attribute">
<dt id="Parameterized.params">
<code class="descname">params</code><a class="headerlink" href="#Parameterized.params" title="Permalink to this definition">¶</a></dt>
<dd><p><em>List[Param]</em> &#8211; A list of all the <code class="code docutils literal"><span class="pre">Param</span></code>s lower in the tree,
sorted by their long name.</p>
</dd></dl>

<dl class="attribute">
<dt id="Parameterized.data_holders">
<code class="descname">data_holders</code><a class="headerlink" href="#Parameterized.data_holders" title="Permalink to this definition">¶</a></dt>
<dd><p><em>List[Param]</em> &#8211; A list of all the <code class="code docutils literal"><span class="pre">DataHolder</span></code>s lower in
the tree, sorted by their long name.</p>
</dd></dl>

<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf</span> <span class="k">import</span> <span class="n">transforms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Parameterized</span><span class="p">(</span><span class="n">Parameterized</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Parameterized</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">Parameterized</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">Param</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Exp</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">Param</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">([</span><span class="mf">10.</span><span class="p">,</span> <span class="mf">23.3</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">42.</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">(</span><span class="mi">23</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="code docutils literal"><span class="pre">.params</span></code> and <code class="code docutils literal"><span class="pre">.data</span></code> attributes return all instances of their
associated types lower in the tree.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">set</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">params</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">param</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">a</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">b</span><span class="p">}</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">set</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">data_holders</span><span class="p">)</span> <span class="o">==</span> <span class="p">{</span><span class="n">m</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">data</span><span class="p">}</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="attribute">
<dt id="gptf.Parameterized.ARRAY_DISPLAY_LENGTH">
<code class="descname">ARRAY_DISPLAY_LENGTH</code><em class="property"> = 5</em><a class="headerlink" href="#gptf.Parameterized.ARRAY_DISPLAY_LENGTH" title="Permalink to this definition">¶</a></dt>
<dd><p>The default array display length.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.NO_DEVICE">
<code class="descname">NO_DEVICE</code><a class="headerlink" href="#gptf.Parameterized.NO_DEVICE" title="Permalink to this definition">¶</a></dt>
<dd><p>When <code class="code docutils literal"><span class="pre">.tf_device</span></code> is set to <code class="code docutils literal"><span class="pre">.NO_DEVICE</span></code>, <code class="code docutils literal"><span class="pre">None</span></code> will be passed
to <code class="code docutils literal"><span class="pre">tf.device()</span></code></p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.children">
<code class="descname">children</code><a class="headerlink" href="#gptf.Parameterized.children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the children of this object at the time of calling.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">(tuple) The current children of the object.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.clear_ancestor_caches">
<code class="descname">clear_ancestor_caches</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.clear_ancestor_caches" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears the caches of direct ancestors.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">AttributeTree</span><span class="p">,</span> <span class="n">TreeWithCache</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child_0</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child_1</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child_0</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">fill_cache</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;123&#39;</span>
<span class="gp">... </span>    <span class="n">t</span><span class="o">.</span><span class="n">child_0</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;456&#39;</span>
<span class="gp">... </span>    <span class="n">t</span><span class="o">.</span><span class="n">child_1</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;789&#39;</span>
<span class="gp">... </span>    <span class="n">t</span><span class="o">.</span><span class="n">child_0</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;ABC&#39;</span>
</pre></div>
</div>
<p>Clearing <code class="code docutils literal"><span class="pre">t.child_0.child</span></code>&#8216;s ancestor&#8217;s cache clears
<code class="code docutils literal"><span class="pre">t</span></code>&#8216;s cache and <code class="code docutils literal"><span class="pre">t.child_0</span></code>&#8216;s cache, but not <code class="code docutils literal"><span class="pre">t.child_1</span></code>&#8216;s or
<code class="code docutils literal"><span class="pre">t.child_0.child</span></code>&#8216;s.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fill_cache</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child_0</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">clear_ancestor_caches</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child_0</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child_1</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">&#39;789&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child_0</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">&#39;ABC&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.clear_cache">
<code class="descname">clear_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.clear_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears this node&#8217;s cache.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">AttributeTree</span><span class="p">,</span> <span class="n">TreeWithCache</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">123</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">123</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">..</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.clear_subtree_caches">
<code class="descname">clear_subtree_caches</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.clear_subtree_caches" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears the cache of this node and every node lower than it.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">AttributeTree</span><span class="p">,</span> <span class="n">TreeWithCache</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">fill_cache</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">123</span>
<span class="gp">... </span>    <span class="n">t</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">456</span>
</pre></div>
</div>
<p>Clearing a parent&#8217;s cache clears its child&#8217;s cache:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fill_cache</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">clear_subtree_caches</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
</pre></div>
</div>
<p>Clearing a child&#8217;s cache does not clear its parent&#8217;s cache:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fill_cache</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">clear_subtree_caches</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">123</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.clear_tree_caches">
<code class="descname">clear_tree_caches</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.clear_tree_caches" title="Permalink to this definition">¶</a></dt>
<dd><p>Clears every cache in the tree.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">AttributeTree</span><span class="p">,</span> <span class="n">TreeWithCache</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">fill_cache</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">123</span>
<span class="gp">... </span>    <span class="n">t</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">456</span>
</pre></div>
</div>
<p>Clearing a parent&#8217;s cache clears its child&#8217;s cache:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fill_cache</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">clear_tree_caches</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
</pre></div>
</div>
<p>Clearing a child&#8217;s cache clears its parent&#8217;s cache:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fill_cache</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">clear_tree_caches</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">t</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">KeyError</span>: <span class="n">message</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.copy">
<code class="descname">copy</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies have empty caches.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.data_holders">
<code class="descname">data_holders</code><a class="headerlink" href="#gptf.Parameterized.data_holders" title="Permalink to this definition">¶</a></dt>
<dd><p>A sorted list of the <code class="code docutils literal"><span class="pre">DataHolder</span></code>s lower in the tree.</p>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.data_summary">
<code class="descname">data_summary</code><span class="sig-paren">(</span><em>array_len=5</em>, <em>fmt='fancy'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#Parameterized.data_summary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Parameterized.data_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>A string table summarizing the data of <code class="code docutils literal"><span class="pre">self</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>array_len</strong> (<em>int</em>) &#8211; The maximum number of elements to display
of each array value.</li>
<li><strong>fmt</strong> (<em>'fancy', 'plain', 'html'</em>) &#8211; The format for the table.
<code class="code docutils literal"><span class="pre">'fancy'</span></code> returns a table with fancy formatting using box
drawing characters and ANSI terminal escape codes.
<code class="code docutils literal"><span class="pre">'plain'</span></code> returns a table using only ascii characters.
<code class="code docutils literal"><span class="pre">'html'</span></code> returns an html table.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A string containing a table specifying the name,
value, transform and prior of each parameter.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(str)</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Parameterized</span><span class="p">(</span><span class="n">Parameterized</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Parameterized</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">fallback_name</span> <span class="o">=</span> <span class="s1">&#39;p&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">Parameterized</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">([[</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data_summary</span><span class="p">(</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;plain&#39;</span><span class="p">))</span>  
<span class="go">name      | value</span>
<span class="go">----------+----------------------</span>
<span class="go">p.child.a | [1.000, 2.000, 3.000]</span>
<span class="go">p.child.b | &lt;np.ndarray&gt;</span>
<span class="go">p.data    | 1.000</span>
</pre></div>
</div>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.feed_dict">
<code class="descname">feed_dict</code><a class="headerlink" href="#gptf.Parameterized.feed_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>The union of the <code class="code docutils literal"><span class="pre">.feed_dict</span></code>s of objects lower in the tree.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.fixed">
<code class="descname">fixed</code><a class="headerlink" href="#gptf.Parameterized.fixed" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether or not params lower in the heirarchy should be fixed.</p>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.get_session">
<code class="descname">get_session</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.get_session" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets a TensorFlow session in which ops can be run.</p>
<p>Returns the default session if there is one. Else, returns a
new session using the session target of the highest parent.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The default session if there is one, else a
session matching the session target of the highest parent.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">(tf.Session)</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf.core.trees</span> <span class="k">import</span> <span class="n">AttributeTree</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AttributeWrappedTF</span><span class="p">(</span><span class="n">WrappedTF</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">AttributeWrappedTF</span><span class="p">()</span>
</pre></div>
</div>
<p>If there is already a default session, returns that
session in a NullContextWrapper.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">sess0</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">sess0</span><span class="p">)</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">sess0</span><span class="o">.</span><span class="n">_NullContextWrapper__wrapped</span> <span class="ow">is</span> <span class="n">sess</span>
<span class="go">NullContextWrapper</span>
<span class="go">True</span>
</pre></div>
</div>
<p>It&#8217;s safe to use w.get_session() in a with block, even if
there is a default session. Doing so won&#8217;t call the
<code class="code docutils literal"><span class="pre">__enter__</span></code> or <code class="code docutils literal"><span class="pre">__exit__</span></code> methods of the default session.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AnnounceSession</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;__enter__ called&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__enter__</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;__exit__ called&#39;</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__exit__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">AnnounceSession</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;before nested with&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">with</span> <span class="n">w</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess0</span><span class="p">:</span>
<span class="gp">... </span>        <span class="k">assert</span> <span class="n">sess</span> <span class="ow">is</span> <span class="n">sess0</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;nested with&#39;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;after nested with&#39;</span><span class="p">)</span>
<span class="go">__enter__ called</span>
<span class="go">before nested with</span>
<span class="go">nested with</span>
<span class="go">after nested with</span>
<span class="go">__exit__ called</span>
</pre></div>
</div>
<p>Else, returns a new session each time:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sess2</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sess2</span> <span class="ow">is</span> <span class="n">sess</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sess3</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sess2</span> <span class="ow">is</span> <span class="n">sess3</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sess2</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sess3</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">WrappedTF</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">op</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>            <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">depth</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">tot</span> <span class="o">=</span> <span class="mi">0</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">tot</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">depth</span><span class="p">()</span>
<span class="gp">... </span>        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">tot</span> <span class="o">+=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">())</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">tot</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># we&#39;re about to do weird things with op placement, and we</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># don&#39;t want it in the default graph where it can mess with</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># other doctests.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tf_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
</pre></div>
</div>
<p><code class="code docutils literal"><span class="pre">Example</span></code> is a simple class that provides a method, <code class="code docutils literal"><span class="pre">.depth()</span></code>,
that uses TensorFlow to calculate an object&#8217;s depth in the tree.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">depth</span><span class="p">()</span>
<span class="go">1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">depth</span><span class="p">()</span>
<span class="go">2</span>
</pre></div>
</div>
<p><code class="code docutils literal"><span class="pre">Example.op()</span></code> places its op based on the hierachical device
context. If we change <code class="code docutils literal"><span class="pre">a</span></code>&#8216;s device context, we also change
<code class="code docutils literal"><span class="pre">a.child</span></code>&#8216;s.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">op</span><span class="p">()</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:worker/task:0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">op</span><span class="p">()</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="go">/job:worker/task:0</span>
</pre></div>
</div>
<p><code class="code docutils literal"><span class="pre">a.child.depth()</span></code> will now result in an error:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">depth</span><span class="p">()</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">tensorflow.python.framework.errors.InvalidArgumentError</span>: <span class="n">...</span>
</pre></div>
</div>
<p><code class="code docutils literal"><span class="pre">a.child.op()</span></code> is now being placed as if it were in a distributed
context, and the default session knows nothing about jobs or tasks.
However, if we set <code class="code docutils literal"><span class="pre">a.session_target</span></code> appropriately,
<code class="code docutils literal"><span class="pre">a.child.get_session()</span></code> will return a session capable of
running ops created with <code class="code docutils literal"><span class="pre">a.child.op_placement_context</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">clusterdict</span> <span class="o">=</span> \
<span class="gp">... </span>    <span class="p">{</span> <span class="s1">&#39;worker&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;localhost:2222&#39;</span><span class="p">]</span>
<span class="gp">... </span>    <span class="p">,</span> <span class="s1">&#39;master&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;localhost:2223&#39;</span><span class="p">]</span>
<span class="gp">... </span>    <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ClusterSpec</span><span class="p">(</span><span class="n">clusterdict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">worker</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Server</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s1">&#39;worker&#39;</span><span class="p">,</span> <span class="n">task_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">worker</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">master</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Server</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s1">&#39;master&#39;</span><span class="p">,</span> <span class="n">task_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tf_session_target</span> <span class="o">=</span> <span class="n">master</span><span class="o">.</span><span class="n">target</span>
</pre></div>
</div>
<p><code class="code docutils literal"><span class="pre">a.child.depth()</span></code> should now run smoothly.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">depth</span><span class="p">()</span>
<span class="go">2</span>
</pre></div>
</div>
<p>In general, this means that as long as the session target of
the root is set correctly, anything lower in the tree that uses
<code class="code docutils literal"><span class="pre">self.get_session()</span></code> should work without fuss.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.highest_parent">
<code class="descname">highest_parent</code><a class="headerlink" href="#gptf.Parameterized.highest_parent" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the highest parent in the tree.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">Tree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_children</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">add_child</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">child</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span>
<span class="gp">... </span>    <span class="nd">@property</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__new__</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">__dict__</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">_children</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">]</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">_set_parent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">copy</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">_unregister_child</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="n">child</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">:</span>
<span class="gp">... </span>            <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
<span class="gp">... </span>            <span class="n">child</span><span class="o">.</span><span class="n">_set_parent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>            <span class="k">raise</span> <span class="n">BadParentError</span>
</pre></div>
</div>
<p>An object at the top of the tree is its own highest parent.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">highest_parent</span> <span class="ow">is</span> <span class="n">p</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Objects lower down in the tree recurse up the tree to find their
highest parent.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">add_child</span><span class="p">(</span><span class="n">Example</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">add_child</span><span class="p">(</span><span class="n">Example</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">highest_parent</span> <span class="ow">is</span> <span class="n">p</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.long_name">
<code class="descname">long_name</code><a class="headerlink" href="#gptf.Parameterized.long_name" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the long name of <code class="code docutils literal"><span class="pre">self</span></code>.</p>
<p>The long name of an object is the concatenation of the names of its
parents, starting from the highest parent.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The full path to the object in the tree.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">(str)</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">Tree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_children</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">add_child</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">child</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span>
<span class="gp">... </span>    <span class="nd">@property</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__new__</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">__dict__</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">_children</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">]</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">_set_parent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">copy</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">_unregister_child</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="n">child</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">:</span>
<span class="gp">... </span>            <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
<span class="gp">... </span>            <span class="n">child</span><span class="o">.</span><span class="n">_set_parent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>            <span class="k">raise</span> <span class="n">BadParentError</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">add_child</span><span class="p">(</span><span class="n">Example</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">children</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">add_child</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">long_name</span><span class="p">)</span>  <span class="c1"># we are not in __main__</span>
<span class="go">unnamed.children[0].children[0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.name">
<code class="descname">name</code><a class="headerlink" href="#gptf.Parameterized.name" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the name by which this object&#8217;s parent refers to it.</p>
<p>If there is no parent, searches <code class="code docutils literal"><span class="pre">globals()</span></code> for a unique alias. If
a unique global alias cannot be found, returns <code class="code docutils literal"><span class="pre">self.fallback_name</span></code>.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">Tree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_children</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">add_child</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">child</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span>
<span class="gp">... </span>    <span class="nd">@property</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__new__</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">__dict__</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">_children</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">]</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">_set_parent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">copy</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">_unregister_child</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="n">child</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">:</span>
<span class="gp">... </span>            <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
<span class="gp">... </span>            <span class="n">child</span><span class="o">.</span><span class="n">_set_parent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>            <span class="k">raise</span> <span class="n">BadParentError</span>
</pre></div>
</div>
<p>Objects at the top of the tree return their name in the global
namespace, if only one such name exists.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># doctest does not run these tests in __main__, but if it</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># did, this would return true.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="ow">not</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span> <span class="ow">or</span> <span class="nb">str</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;p&#39;</span>
<span class="go">True</span>
</pre></div>
</div>
<p>If no unique global aliases to the root exists, <code class="code docutils literal"><span class="pre">.fallback_name</span></code>
is returned.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="n">p</span>  <span class="c1"># now p has two global aliases, &#39;p&#39; and &#39;q&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">p</span><span class="o">.</span><span class="n">fallback_name</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Otherwise, an object&#8217;s name is the name its parent gives it,
as return by <code class="code docutils literal"><span class="pre">child.parent.name_of(child)</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">add_child</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">.children[0]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.name_of">
<code class="descname">name_of</code><span class="sig-paren">(</span><em>value</em><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.name_of" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the name of <code class="code docutils literal"><span class="pre">value</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">A name by which <code class="code docutils literal"><span class="pre">value</span></code> can be accessed from <code class="code docutils literal"><span class="pre">self</span></code>. If
<code class="code docutils literal"><span class="pre">self</span></code> is accessible by some variable <code class="code docutils literal"><span class="pre">p</span></code>, then
<code class="code docutils literal"><span class="pre">eval(&quot;p&quot;</span> <span class="pre">+</span> <span class="pre">p.name_of(value))</span></code> must return <code class="code docutils literal"><span class="pre">value</span></code>, assuming
<code class="code docutils literal"><span class="pre">p.name_of()</span></code> doesn&#8217;t raise.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">(str)</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><code class="xref py py-exc docutils literal"><span class="pre">BadParentError</span></code> &#8211; If <code class="code docutils literal"><span class="pre">value</span></code> is not a child of <code class="code docutils literal"><span class="pre">self</span></code>.</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">Tree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_children</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">add_child</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">child</span><span class="o">.</span><span class="n">parent</span> <span class="o">=</span> <span class="bp">self</span>
<span class="gp">... </span>    <span class="nd">@property</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">children</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">copy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__new__</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">))</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">__dict__</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">_children</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">]</span>
<span class="gp">... </span>        <span class="n">copy</span><span class="o">.</span><span class="n">_set_parent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">copy</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">_unregister_child</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="n">child</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="p">:</span>
<span class="gp">... </span>            <span class="bp">self</span><span class="o">.</span><span class="n">_children</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">child</span><span class="p">)</span>
<span class="gp">... </span>            <span class="n">child</span><span class="o">.</span><span class="n">_set_parent</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>            <span class="k">raise</span> <span class="n">BadParentError</span>
</pre></div>
</div>
<p>In the default implementation, this returns <code class="code docutils literal"><span class="pre">'.children[x]'</span></code>
where <code class="code docutils literal"><span class="pre">x</span></code> is <code class="code docutils literal"><span class="pre">self.children.index(value)</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">add_child</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">name_of</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
<span class="go">&#39;.children[0]&#39;</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.on_session_birth">
<code class="descname">on_session_birth</code><span class="sig-paren">(</span><em>session</em><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.on_session_birth" title="Permalink to this definition">¶</a></dt>
<dd><p>Called just after a session is created.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>session</strong> (<em>tf.Session</em>) &#8211; The created session.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.on_session_death">
<code class="descname">on_session_death</code><span class="sig-paren">(</span><em>session</em><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.on_session_death" title="Permalink to this definition">¶</a></dt>
<dd><p>Called just before a session is closed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>session</strong> (<em>tf.Session</em>) &#8211; The dying session.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.op_placement_context">
<code class="descname">op_placement_context</code><span class="sig-paren">(</span><em>name_scope=True</em><span class="sig-paren">)</span><a class="headerlink" href="#gptf.Parameterized.op_placement_context" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies op placement rules based on the object hierarchy.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf.core.trees</span> <span class="k">import</span> <span class="n">AttributeTree</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">WrappedTF</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">tf_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
</pre></div>
</div>
<p>Choose the op placement context by assigning to <code class="code docutils literal"><span class="pre">.tf_device</span></code>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">e</span> <span class="o">=</span> <span class="p">[</span><span class="n">Example</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:worker&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">DeviceSpec</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="p">,</span> <span class="n">device_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="kc">None</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">NO_DEVICE</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:spoon&#39;</span>
</pre></div>
</div>
<p>Device contexts are combined, starting from the context of the
root of the tree. <code class="code docutils literal"><span class="pre">c.tf_device</span></code> is <code class="code docutils literal"><span class="pre">None</span></code>, so it uses the context
of its parent.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">c</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">a</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="go">/job:worker</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">c</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="go">/job:worker</span>
</pre></div>
</div>
<p><code class="code docutils literal"><span class="pre">d.tf_device</span></code> is <code class="code docutils literal"><span class="pre">WrappedTF.NO_DEVICE</span></code>, so it resets the device
context.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">d</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">d</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p>Other device contexts combine the way you would expect them to.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">b</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">e</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">b</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="c1"># get job from a</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="go">/job:worker/device:GPU:0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">e</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="c1"># get device from b, overwrite job from a</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="go">/job:spoon/device:GPU:0</span>
</pre></div>
</div>
<p>The root node of the tree may define a <code class="code docutils literal"><span class="pre">.tf_graph</span></code>. Child ops will
be placed in the <code class="code docutils literal"><span class="pre">.tf_graph</span></code> of their highest parent.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span><span class="o">.</span><span class="n">tf_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">tf_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">a</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">graph</span> <span class="ow">is</span> <span class="n">a</span><span class="o">.</span><span class="n">tf_graph</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">b</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">graph</span> <span class="ow">is</span> <span class="n">a</span><span class="o">.</span><span class="n">tf_graph</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">e</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">graph</span> <span class="ow">is</span> <span class="n">a</span><span class="o">.</span><span class="n">tf_graph</span>
<span class="go">True</span>
</pre></div>
</div>
<p>In addition, a name scope is opened that matches the object
hierachy:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">a</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed/Const...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">b</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed.child/Const...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">e</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">():</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed.child.child/Const...</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.param_summary">
<code class="descname">param_summary</code><span class="sig-paren">(</span><em>array_len=5</em>, <em>fmt='fancy'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#Parameterized.param_summary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Parameterized.param_summary" title="Permalink to this definition">¶</a></dt>
<dd><p>A string table summarizing the parameters of <code class="code docutils literal"><span class="pre">self</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>fmt</strong> (<em>'fancy', 'plain', 'html'</em>) &#8211; The format for the table.
<code class="code docutils literal"><span class="pre">'fancy'</span></code> returns a table with fancy formatting using box
drawing characters and ANSI terminal escape codes.
<code class="code docutils literal"><span class="pre">'plain'</span></code> returns a table using only ascii characters.
<code class="code docutils literal"><span class="pre">'html'</span></code> returns an html table.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A string containing a table specifying the name,
value, transform and prior of each parameter.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">(str)</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf</span> <span class="k">import</span> <span class="n">transforms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Parameterized</span><span class="p">(</span><span class="n">Parameterized</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Parameterized</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">fallback_name</span> <span class="o">=</span> <span class="s1">&#39;p&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">Parameterized</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">Param</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">Param</span><span class="p">([[</span><span class="mf">1.</span><span class="p">]],</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Exp</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">param_summary</span><span class="p">(</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;plain&#39;</span><span class="p">))</span>  
<span class="go">name      | value                 | transform | prior</span>
<span class="go">----------+-----------------------+-----------+------</span>
<span class="go">p.child.a | [1.000, 2.000, 3.000] | identity  | nyi</span>
<span class="go">p.child.b | &lt;np.ndarray&gt;          | +ve (Exp) | nyi</span>
<span class="go">p.param   | 1.000                 | identity  | nyi</span>
</pre></div>
</div>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.params">
<code class="descname">params</code><a class="headerlink" href="#gptf.Parameterized.params" title="Permalink to this definition">¶</a></dt>
<dd><p>A sorted list of the <code class="code docutils literal"><span class="pre">Param</span></code>s lower in the tree.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.parent">
<code class="descname">parent</code><a class="headerlink" href="#gptf.Parameterized.parent" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the direct parent.</p>
</dd></dl>

<dl class="method">
<dt id="gptf.Parameterized.summary">
<code class="descname">summary</code><span class="sig-paren">(</span><em>array_len=5</em>, <em>fmt='fancy'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#Parameterized.summary"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Parameterized.summary" title="Permalink to this definition">¶</a></dt>
<dd><p>A string table summarizing <code class="code docutils literal"><span class="pre">self</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>array_len</strong> (<em>int</em>) &#8211; The maximum number of elements to display
of each array value.</li>
<li><strong>fmt</strong> (<em>'fancy', 'plain', 'html'</em>) &#8211; The format for the table.
<code class="code docutils literal"><span class="pre">'fancy'</span></code> returns a table with fancy formatting using box
drawing characters and ANSI terminal escape codes.
<code class="code docutils literal"><span class="pre">'plain'</span></code> returns a table using only ascii characters.
<code class="code docutils literal"><span class="pre">'html'</span></code> returns an html table.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A summary of this object&#8217;s parameters and data.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(str)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.tf_device">
<code class="descname">tf_device</code><a class="headerlink" href="#gptf.Parameterized.tf_device" title="Permalink to this definition">¶</a></dt>
<dd><p>The device context onto which this object&#8217;s ops should be pinned.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.tf_graph">
<code class="descname">tf_graph</code><a class="headerlink" href="#gptf.Parameterized.tf_graph" title="Permalink to this definition">¶</a></dt>
<dd><p>The graph to place ops in.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Parameterized.tf_session_target">
<code class="descname">tf_session_target</code><a class="headerlink" href="#gptf.Parameterized.tf_session_target" title="Permalink to this definition">¶</a></dt>
<dd><p>The target under which sessions should be run.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="gptf.ParamAttributes">
<em class="property">class </em><code class="descclassname">gptf.</code><code class="descname">ParamAttributes</code><a class="reference internal" href="_modules/gptf/core/params.html#ParamAttributes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.ParamAttributes" title="Permalink to this definition">¶</a></dt>
<dd><p>Parameters are accessed using attributes.</p>
<dl class="method">
<dt id="gptf.ParamAttributes.__setattr__">
<code class="descname">__setattr__</code><span class="sig-paren">(</span><em>name</em>, <em>value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#ParamAttributes.__setattr__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.ParamAttributes.__setattr__" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the value of <code class="code docutils literal"><span class="pre">Param</span></code>s and <code class="code docutils literal"><span class="pre">DataHolder</span></code>s on assignment.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name</strong> (<em>str</em>) &#8211; The name of the attribute.</li>
<li><strong>value</strong> &#8211; The value to set.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>Assigning a numerical, numpy or string value to a <code class="code docutils literal"><span class="pre">Param</span></code> or
<code class="code docutils literal"><span class="pre">DataHolder</span></code> child assigns to that child&#8217;s value instead.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">ParamAttributes</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">param</span><span class="p">,</span> <span class="n">Param</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">param</span><span class="o">.</span><span class="n">value</span>
<span class="go">array(2.0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">DataHolder</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">value</span>
<span class="go">array(2.0)</span>
</pre></div>
</div>
<p>Assigning anything else overwrites the attribute:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">():</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">param</span><span class="p">,</span> <span class="n">Example</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">Example</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Children still know who their parents are.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">param</span><span class="o">.</span><span class="n">parent</span> <span class="ow">is</span> <span class="n">p</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="gptf.ParamList">
<em class="property">class </em><code class="descclassname">gptf.</code><code class="descname">ParamList</code><span class="sig-paren">(</span><em>initial_values=()</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#ParamList"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.ParamList" title="Permalink to this definition">¶</a></dt>
<dd><p>A list of <code class="code docutils literal"><span class="pre">Param</span></code> or <code class="code docutils literal"><span class="pre">DataHolder</span></code> objects.</p>
<p class="rubric">Examples</p>
<p>You can set the value of children by assigning to their index:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">ParamList</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Param</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">DataHolder</span><span class="p">(</span><span class="mf">1.</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">3.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Param</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
<span class="go">array(3.0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">DataHolder</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">value</span>
<span class="go">array(5.0)</span>
</pre></div>
</div>
<p>You can still overwrite parameters etc with new ones:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">ParamAttributes</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Param</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="gptf.Param">
<em class="property">class </em><code class="descclassname">gptf.</code><code class="descname">Param</code><span class="sig-paren">(</span><em>initial_value</em>, <em>transform=gptf.core.transforms.Identity()</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#Param"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Param" title="Permalink to this definition">¶</a></dt>
<dd><p>A parameter of a model.</p>
<p>Instances have all attributes of <code class="code docutils literal"><span class="pre">WrappedValue</span></code> and the following:</p>
<dl class="attribute">
<dt id="Param.value">
<code class="descname">value</code><a class="headerlink" href="#Param.value" title="Permalink to this definition">¶</a></dt>
<dd><p><em>np.ndarray</em> &#8211; The value of the parameter.</p>
</dd></dl>

<dl class="attribute">
<dt id="Param.tensor">
<code class="descname">tensor</code><a class="headerlink" href="#Param.tensor" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf.Tensor</em> &#8211; A tensor representation of the parameter,
suitable for passing to TensorFlow ops.</p>
</dd></dl>

<dl class="attribute">
<dt id="Param.feed_dict">
<code class="descname">feed_dict</code><a class="headerlink" href="#Param.feed_dict" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Dict</em> &#8211; Currently an empty dictionary.</p>
</dd></dl>

<dl class="attribute">
<dt id="Param.free_state">
<code class="descname">free_state</code><a class="headerlink" href="#Param.free_state" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf.Variable</em> &#8211; The free state form of the parameter, that
can be freely optimised.</p>
</dd></dl>

<dl class="attribute">
<dt id="Param.fixed">
<code class="descname">fixed</code><a class="headerlink" href="#Param.fixed" title="Permalink to this definition">¶</a></dt>
<dd><p><em>bool</em> &#8211; A flag indicating whether or not the variable is fixed.
Fixed parameters will not be optimised.</p>
</dd></dl>

<dl class="attribute">
<dt id="Param.transform">
<code class="descname">transform</code><a class="headerlink" href="#Param.transform" title="Permalink to this definition">¶</a></dt>
<dd><p><em>.transforms.Transform</em> &#8211; The transform used to move the
variable into a free state where it can be optimised.</p>
</dd></dl>

<p class="rubric">Examples</p>
<p class="rubric">Getting and setting values</p>
<p>You can get and set the (numpy) value of a <code class="code docutils literal"><span class="pre">Param</span></code> using its
<code class="code docutils literal"><span class="pre">value</span></code> attribute:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">value</span>
<span class="go">array(1.0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">value</span>
<span class="go">array(2.0)</span>
</pre></div>
</div>
<p>A tensor representing the paremeter can be acquired using the
<code class="code docutils literal"><span class="pre">tensor</span></code> attribute.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">isinstance</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">tensor</span><span class="p">))</span>
<span class="go">2.0</span>
</pre></div>
</div>
<p>Behind the scenes, this creates a <code class="code docutils literal"><span class="pre">tf.Variable</span></code>, accessible using the
<code class="code docutils literal"><span class="pre">free_state</span></code> attribute. We can use this variable in a session like so:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.free_state: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">)))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
<span class="gp">... </span>    <span class="c1"># assigning to p.value changes p.free_state</span>
<span class="gp">... </span>    <span class="n">p</span><span class="o">.</span><span class="n">value</span> <span class="o">+=</span> <span class="mf">1.0</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.free_state: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">)))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
<span class="gp">... </span>    <span class="c1"># assigning to p.free_state changes p.value</span>
<span class="gp">... </span>    <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.free_state: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">)))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
<span class="go">.free_state: 2.0</span>
<span class="go">.value: 2.0</span>
<span class="go">.free_state: 3.0</span>
<span class="go">.value: 3.0</span>
<span class="go">.free_state: 4.0</span>
<span class="go">.value: 4.0</span>
</pre></div>
</div>
<p>The session returned by <code class="code docutils literal"><span class="pre">p.get_session()</span></code> maintains the value of
<code class="code docutils literal"><span class="pre">p.free_state</span></code> across uses:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">))</span>
<span class="go">4.0</span>
</pre></div>
</div>
<p>If we have multiple <code class="code docutils literal"><span class="pre">Param</span></code>s, as long as they are in the same
tree of <code class="code docutils literal"><span class="pre">WrappedTF</span></code>, each <code class="code docutils literal"><span class="pre">Param</span></code>&#8216;s <code class="code docutils literal"><span class="pre">.get_session()</span></code> will return
the same session, and every <code class="code docutils literal"><span class="pre">Param</span></code> in the tree will have its free
state maintained in that session.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AttributeWrappedTF</span><span class="p">(</span><span class="n">WrappedTF</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">AttributeWrappedTF</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">q</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">w</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">q</span><span class="o">.</span><span class="n">free_state</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="go">2.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">w</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">q</span><span class="o">.</span><span class="n">free_state</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="go">2.0</span>
</pre></div>
</div>
<p>It is possible to use <code class="code docutils literal"><span class="pre">tf.Session()</span></code> instead of <code class="code docutils literal"><span class="pre">p.get_session()</span></code>.
In that case, we must run <code class="code docutils literal"><span class="pre">p.on_session_birth()</span></code> after the session
has been installed as the default session and <code class="code docutils literal"><span class="pre">p.on_session_death()</span></code>
just before the session closes.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">p</span><span class="o">.</span><span class="n">on_session_birth</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.free_state: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">)))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
<span class="gp">... </span>    <span class="c1"># assiging to p.value changes p.free_state</span>
<span class="gp">... </span>    <span class="n">p</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="o">.</span><span class="mi">0</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.free_state: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">)))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
<span class="gp">... </span>    <span class="c1"># assigning to p.free_state does not change p.value</span>
<span class="gp">... </span>    <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.free_state: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">)))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;.value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">))</span>
<span class="gp">... </span>    <span class="n">p</span><span class="o">.</span><span class="n">on_session_death</span><span class="p">(</span><span class="n">sess</span><span class="p">)</span>
<span class="go">.free_state: 4.0</span>
<span class="go">.value: 4.0</span>
<span class="go">.free_state: 0.0</span>
<span class="go">.value: 0.0</span>
<span class="go">.free_state: 1.0</span>
<span class="go">.value: 1.0</span>
</pre></div>
</div>
<p>We advise the reader to use <code class="code docutils literal"><span class="pre">p.get_session()</span></code>.</p>
<p>Attempting to set the tensor or free_state paremeters results in an
error:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">AttributeError</span>: <span class="n">can&#39;t set attribute</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">AttributeError</span>: <span class="n">can&#39;t set attribute</span>
</pre></div>
</div>
<p class="rubric">Fixing parameters</p>
<p>A parameter can be fixed by setting the <code class="code docutils literal"><span class="pre">.fixed</span></code> attribute to <code class="code docutils literal"><span class="pre">True</span></code>.
A fixed parameter should not be optimised. Attempting to
access the <code class="code docutils literal"><span class="pre">.free_state</span></code> attribute of a fixed parameter will result
in a <code class="code docutils literal"><span class="pre">FixedParameterError</span></code>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">fixed</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">gptf.core.params.FixedParameterError</span>: <span class="n">message</span>
</pre></div>
</div>
<p>Ultimately, however, it is the responsibility of the optimiser to
respect this flag. See the <code class="code docutils literal"><span class="pre">Parameterised</span></code> and <code class="code docutils literal"><span class="pre">Model</span></code> classes for
more details.</p>
<p class="rubric">Transforms</p>
<p>Constraints can be applied to a parameter in the form of <code class="code docutils literal"><span class="pre">Transform</span></code>s.
A <code class="code docutils literal"><span class="pre">Transform</span></code> is used to transform the parameter into a free state,
where it can then be optimized. The transform can be set either by
specifying <code class="code docutils literal"><span class="pre">transform</span></code> paramater of the constructor or after creation
using the <code class="code docutils literal"><span class="pre">.transform</span></code> attribute. The default transform is
<code class="code docutils literal"><span class="pre">gptf.transforms.Identity</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf</span> <span class="k">import</span> <span class="n">transforms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span>
<span class="go">gptf.core.transforms.Identity()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Exp</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">transform</span>
<span class="go">gptf.core.transforms.Exp(lower=1e-06)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">transform</span>
<span class="go">gptf.core.transforms.Identity()</span>
</pre></div>
</div>
<p>The associated free state can be obtained using the <code class="code docutils literal"><span class="pre">.free_state</span></code>
parameter.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Exp</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3e}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">)))</span>
<span class="go">1.0</span>
<span class="go">-1.000e-06</span>
</pre></div>
</div>
<p>The free state can then be freely optimised, and <code class="code docutils literal"><span class="pre">p.value</span></code> and
<code class="code docutils literal"><span class="pre">p.tensor</span></code> will remain constrained by the transform.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Exp</span><span class="p">())</span>  <span class="c1"># p.value &gt; 0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">_</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span> <span class="o">==</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">tensor</span><span class="p">))</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="go">True</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Tensorflow will take the transform into account when calculating
the derivative of <code class="code docutils literal"><span class="pre">p.tensor</span></code> w.r.t. its free state:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">math</span> <span class="k">import</span> <span class="n">e</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_identity</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">tensor</span><span class="p">],</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">grad_identity</span><span class="p">))</span>
<span class="go">1.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Exp</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">grad_exp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gradients</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">tensor</span><span class="p">],</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">p</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">grad_exp</span><span class="p">)))</span>
<span class="go">2.718</span>
</pre></div>
</div>
<p class="rubric">Copies</p>
<p>You can create a copy of a <code class="code docutils literal"><span class="pre">Param</span></code> using <code class="code docutils literal"><span class="pre">Param.copy()</span></code>. The
new copy represents the same parameter, so the value and
various items of state (see below) are the same.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Exp</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
<p>Copies have the same value as the original, and updating the
value of the copy updates the value of the original.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">copy</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="mf">5.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span><span class="o">.</span><span class="n">value</span>
<span class="go">array(5.0)</span>
</pre></div>
</div>
<p>Copies have the same transform, and setting the transform
of a copy sets the transform of the original.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="n">p</span><span class="o">.</span><span class="n">transform</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">transform</span>
<span class="go">gptf.core.transforms.Identity()</span>
</pre></div>
</div>
<p>Copies have the same &#8220;fixed&#8221; flag. Fixing a copy fixes the
original and vice-versa.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">fixed</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span><span class="o">.</span><span class="n">fixed</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span><span class="o">.</span><span class="n">fixed</span> <span class="o">=</span> <span class="kc">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">fixed</span>
<span class="go">False</span>
</pre></div>
</div>
<p>Copies have the same free state.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p</span><span class="o">.</span><span class="n">free_state</span> <span class="ow">is</span> <span class="n">copy</span><span class="o">.</span><span class="n">free_state</span>
<span class="go">True</span>
</pre></div>
</div>
<p>This means that it is <em>very important</em> that every copy of of a
<code class="code docutils literal"><span class="pre">Param</span></code> has the same device context and graph, or odd things
happen.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AttributeWrappedTF</span><span class="p">(</span><span class="n">AttributeTree</span><span class="p">,</span> <span class="n">WrappedTF</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">treeparam</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">AttributeWrappedTF</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">treeparam</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">AttributeWrappedTF</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">treeparam</span>  <span class="c1"># creates a copy of the param</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">tf_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:spoon/task:0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:knife/task:0&#39;</span>
</pre></div>
</div>
<p>In the above example, where should we place
<code class="code docutils literal"><span class="pre">treeparam.free_state</span></code>? Should it be on <code class="code docutils literal"><span class="pre">'/job:spoon/task:0'</span></code>
where <code class="code docutils literal"><span class="pre">w.param</span></code> is, or on <code class="code docutils literal"><span class="pre">'/job:knife/task:0'</span></code> where
<code class="code docutils literal"><span class="pre">w.child.param</span></code> is? Currently, there is no system in place
to resolve this. In this situation, one should define the
device context of <code class="code docutils literal"><span class="pre">treeparam</span></code> explicitly:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">treeparam</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:spoon&#39;</span>
</pre></div>
</div>
<p>To create a new param with the same value, pass the value to
<code class="code docutils literal"><span class="pre">Param.__init__()</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">notacopy</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">p</span><span class="o">.</span><span class="n">transform</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="gptf.Param.clear_cache">
<code class="descname">clear_cache</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#Param.clear_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Param.clear_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>Save the variable value before it is cleared from the cache.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Param.feed_dict">
<code class="descname">feed_dict</code><a class="headerlink" href="#gptf.Param.feed_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>An empty dictionary.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Param.fixed">
<code class="descname">fixed</code><a class="headerlink" href="#gptf.Param.fixed" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether or not the parameter is fixed.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Param.free_state">
<code class="descname">free_state</code><a class="headerlink" href="#gptf.Param.free_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a variable that maps to the free state of the parameter.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Param.initializer">
<code class="descname">initializer</code><a class="headerlink" href="#gptf.Param.initializer" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialises the internal <code class="code docutils literal"><span class="pre">tf.Variable</span></code> to the correct value.</p>
<p>This op is automatically run for sessions obtained using
<code class="code docutils literal"><span class="pre">.get_session()</span></code>.</p>
</dd></dl>

<dl class="method">
<dt id="gptf.Param.on_session_birth">
<code class="descname">on_session_birth</code><span class="sig-paren">(</span><em>session</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#Param.on_session_birth"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Param.on_session_birth" title="Permalink to this definition">¶</a></dt>
<dd><p>Called just after a session is created.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>session</strong> (<em>tf.Session</em>) &#8211; The created session.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.Param.on_session_death">
<code class="descname">on_session_death</code><span class="sig-paren">(</span><em>session</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#Param.on_session_death"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Param.on_session_death" title="Permalink to this definition">¶</a></dt>
<dd><p>Called just before a session is closed.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>session</strong> (<em>tf.Session</em>) &#8211; The dying session.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Param.tensor">
<code class="descname">tensor</code><a class="headerlink" href="#gptf.Param.tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a tensor representing the value of the parameter.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">(tf.Tensor) The forward transform of the parameter applied to its
free state.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="gptf.Param.transform">
<code class="descname">transform</code><a class="headerlink" href="#gptf.Param.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>The transform between the free space and value space.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="gptf.DataHolder">
<em class="property">class </em><code class="descclassname">gptf.</code><code class="descname">DataHolder</code><span class="sig-paren">(</span><em>initial_value</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#DataHolder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.DataHolder" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds data to be fed into TensorFlow for computation.</p>
<dl class="attribute">
<dt id="DataHolder.value">
<code class="descname">value</code><a class="headerlink" href="#DataHolder.value" title="Permalink to this definition">¶</a></dt>
<dd><p><em>np.ndarray</em> &#8211; The value of the data.</p>
</dd></dl>

<dl class="attribute">
<dt id="DataHolder.tensor">
<code class="descname">tensor</code><a class="headerlink" href="#DataHolder.tensor" title="Permalink to this definition">¶</a></dt>
<dd><p><em>tf.placeholder</em> &#8211; A placeholder for the data,
suitable for passing to TensorFlow ops.</p>
</dd></dl>

<dl class="attribute">
<dt id="DataHolder.feed_dict">
<code class="descname">feed_dict</code><a class="headerlink" href="#DataHolder.feed_dict" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Dict[tf.placeholder, np.array_like]</em> &#8211; A feed dictionary
that feeds the value of the data into the placeholder op.</p>
</dd></dl>

<dl class="attribute">
<dt id="DataHolder.on_shape_change">
<code class="descname">on_shape_change</code><a class="headerlink" href="#DataHolder.on_shape_change" title="Permalink to this definition">¶</a></dt>
<dd><p><em>&#8216;raise&#8217; | &#8216;pass&#8217; | &#8216;recompile&#8217;</em> &#8211; The action to take
when the shape of the data changes; see the setter for <code class="code docutils literal"><span class="pre">.value</span></code>.</p>
</dd></dl>

<p class="rubric">Examples</p>
<p class="rubric">Getting and setting values</p>
<p>To get and set the value of the data, use the <code class="code docutils literal"><span class="pre">.value</span></code> property:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">value</span>
<span class="go">array([1, 2, 3])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">b</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">value</span>
<span class="go">array([4, 5, 6])</span>
</pre></div>
</div>
<p>See the docs for <code class="code docutils literal"><span class="pre">gptf.core.params.WrappedValue</span></code> for more info.</p>
<p>To access the value from TensorFlow, first build an op that relies
on the <code class="code docutils literal"><span class="pre">.tensor</span></code> attribute:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">tensor</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Then evaluate the op in a session, passing in the feed dictionary
to <code class="code docutils literal"><span class="pre">tf.Session.run()</span></code>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">d</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">d</span><span class="o">.</span><span class="n">feed_dict</span><span class="p">)</span>
<span class="go">array([2, 3, 4])</span>
</pre></div>
</div>
<p class="rubric">Copies</p>
<p>You can create a copy of a <code class="code docutils literal"><span class="pre">DataHolder</span></code> using <code class="code docutils literal"><span class="pre">.copy()</span></code>. The
new copy represents the same data, so the value and
various items of state (see below) are the same.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
<p>Copies have the same value as the original, and updating the
value of the copy updates the value of the original.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">copy</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="p">[</span><span class="mf">5.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">copy</span><span class="o">.</span><span class="n">value</span>
<span class="go">array([ 5., 4., 3.])</span>
</pre></div>
</div>
<p>Copies have the same placeholder.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">d</span><span class="o">.</span><span class="n">tensor</span> <span class="ow">is</span> <span class="n">copy</span><span class="o">.</span><span class="n">tensor</span>
<span class="go">True</span>
</pre></div>
</div>
<p>This means that it, just in the case of <code class="code docutils literal"><span class="pre">Param</span></code>s, it is
<em>very important</em> that every copy of a <code class="code docutils literal"><span class="pre">DataHolder</span></code> has the
same device context and graph, or odd things happen.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">AttributeWrappedTF</span><span class="p">(</span><span class="n">AttributeTree</span><span class="p">,</span> <span class="n">WrappedTF</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">treedata</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">AttributeWrappedTF</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">treedata</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">AttributeWrappedTF</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">treedata</span>  <span class="c1"># creates a copy of the data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">tf_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:spoon/task:0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:knife/task:0&#39;</span>
</pre></div>
</div>
<p>In circumstances like the above, where copies have
conflicting parental device contexts, set the device
context explicitly.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">treedata</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:spoon&#39;</span>
</pre></div>
</div>
<p>To create a new dataholder with the same value, pass the value
to <code class="code docutils literal"><span class="pre">DataHolder.__init__()</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">notacopy</span> <span class="o">=</span> <span class="n">DataHolder</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
<dl class="attribute">
<dt id="gptf.DataHolder.feed_dict">
<code class="descname">feed_dict</code><a class="headerlink" href="#gptf.DataHolder.feed_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>A dict that feeds the value of the data into its placeholder.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.DataHolder.tensor">
<code class="descname">tensor</code><a class="headerlink" href="#gptf.DataHolder.tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>The placeholder that the data will be fed into.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="gptf.tf_method">
<code class="descclassname">gptf.</code><code class="descname">tf_method</code><span class="sig-paren">(</span><em>name_scope=True</em>, <em>rename_output=True</em>, <em>cache=True</em>, <em>cache_limit=128</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/wrappedtf.html#tf_method"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.tf_method" title="Permalink to this definition">¶</a></dt>
<dd><p>Decorator version of <code class="code docutils literal"><span class="pre">WrappedTF.op_placement_context</span></code>.</p>
<p>Applies <code class="code docutils literal"><span class="pre">instance.op_placement_context(name_scope=False)</span></code>
to <code class="code docutils literal"><span class="pre">instance.method(...)</span></code></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>name_scope</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">True</span></code>, wraps the function in an
appropriate <code class="code docutils literal"><span class="pre">tf.name_scope()</span></code>.</li>
<li><strong>cache</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">True</span></code>, applies caching to the function.
Multiple calls with the same arguments will return
the same result. See examples.</li>
<li><strong>cache_limit</strong> (<em>int</em>) &#8211; The limit for the cache.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>In the following example, <code class="code docutils literal"><span class="pre">Example.method_a</span></code> is equivalent
to <code class="code docutils literal"><span class="pre">Example.method_b</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf.core.trees</span> <span class="k">import</span> <span class="n">AttributeTree</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">WrappedTF</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">method_a</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">op_placement_context</span><span class="p">(</span><span class="n">name_scope</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="gp">... </span>            <span class="n">scope</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">long_name</span> <span class="o">+</span> <span class="s1">&#39;.method_a/&#39;</span>
<span class="gp">... </span>            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">scope</span><span class="p">):</span>
<span class="gp">... </span>                <span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="gp">... </span>                <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;0&#39;</span><span class="p">)</span>  <span class="c1">#scope[:-1])</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">method_b</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>
</div>
<p>Devices are set properly in both methods:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">e</span> <span class="o">=</span> <span class="n">Example</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">tf_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>  <span class="c1"># don&#39;t break other doctests</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:worker/task:0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">method_a</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="go">/job:worker/task:0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">method_b</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">a</span><span class="o">.</span><span class="n">device</span>
<span class="go">True</span>
</pre></div>
</div>
<p>The returned tensor(s) are given the name of the name scope.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed.method_a/0:0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed.method_b/0:0</span>
</pre></div>
</div>
<p>Multiple method calls produce unique names.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">method_b</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed.method_b/0_1:0</span>
</pre></div>
</div>
<p>If a method returns a sequence of tensors, they are named
<code class="code docutils literal"><span class="pre">&lt;scope&gt;/0</span></code>, <code class="code docutils literal"><span class="pre">&lt;scope&gt;/1</span></code>, etc.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">DoubleReturnExample</span><span class="p">(</span><span class="n">WrappedTF</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">(</span><span class="n">cache</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">obj</span> <span class="o">=</span> <span class="n">DoubleReturnExample</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">method</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed.method/0:0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed.method/1:0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">method</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed.method/0_1:0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="go">unnamed.method/1_1:0</span>
</pre></div>
</div>
<p>Calls to other tensorflow methods do not cause nested name scopes.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">NestedExample</span><span class="p">(</span><span class="n">WrappedTF</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">child</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">child</span> <span class="o">=</span> <span class="n">child</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">child</span><span class="o">.</span><span class="n">method_b</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">NestedExample</span><span class="p">(</span><span class="n">Example</span><span class="p">())</span><span class="o">.</span><span class="n">method</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="go">unnamed.child.method_b/0:0</span>
</pre></div>
</div>
<p>Else, no attempt is made to rename the output.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">NumpyReturnExample</span><span class="p">(</span><span class="n">WrappedTF</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">NumpyReturnExample</span><span class="p">()</span><span class="o">.</span><span class="n">method</span><span class="p">()</span>
<span class="go">1</span>
</pre></div>
</div>
<p>If caching is enabled, then multiple calls with the same
arguments will result in the same return value.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">method_b</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="ow">is</span> <span class="n">e</span><span class="o">.</span><span class="n">method_b</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<p>This means that ops are not added to the graph multiple times
for identical method calls, which is a good thing.</p>
<p>If the cache is cleared (perhaps due to a device context
change), the method cache is also cleared, and new tensors
will be returned.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">e</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tensor</span> <span class="ow">is</span> <span class="n">e</span><span class="o">.</span><span class="n">method_b</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="go">False</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="autoflow">
<h2>Autoflow<a class="headerlink" href="#autoflow" title="Permalink to this headline">¶</a></h2>
<p>The autoflow decorator allows you to define a method of a parameterized class
using Tensorflow, but interact with it using NumPy. It applies
<a class="reference internal" href="#gptf.tf_method" title="gptf.tf_method"><code class="xref py py-func docutils literal"><span class="pre">gptf.tf_method()</span></code></a> for you.</p>
<dl class="function">
<dt>
<code class="descclassname">gptf.</code><code class="descname">autoflow</code><span class="sig-paren">(</span><em>*placeholder_specs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/params.html#autoflow"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Wraps up a TensorFlow method so that it takes NumPy and gives NumPy.</p>
<p>When an autoflowed method is called, we construct placeholders to
represent the passed arguments, apply <code class="code docutils literal"><span class="pre">tf_method</span></code>
to the wrapped method and evaluate it on the placeholders to produce
a TensorFlow op. We then evaluate the op in a session, passing in the
appropriate feed dictionaries, and return the resulting NumPy array.</p>
<p>We also cache the op, so that multiple calls to the function construct
the op only once. This cache is cleared when device contexts change,
when transforms on <code class="code docutils literal"><span class="pre">Param</span></code>s change, and any number of other similar
circumstances.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>*placeholder_specs</strong> &#8211; some tuples that specify how the placeholders
for the arguments of the decorated method should be
constructed. Each tuple will be used as the arguments to a
call to <code class="code docutils literal"><span class="pre">tf.placeholder()</span></code>. The first tuple will be used to
construct the placeholder for the first argument of the
decorated function, the second for the second, and so on.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">A decorator that autoflows the decorated method.</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>The decorator syntax looks like this:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">MyClass</span><span class="p">(</span><span class="n">Parameterized</span><span class="p">,</span> <span class="n">AttributeTree</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nd">@autoflow</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">,),</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">,))</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">tf_add</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="nd">@autoflow</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="kc">None</span><span class="p">]))</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">tf_reduce_sum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we can leverage the mighty power of tensorflow without ever
having to get our hands dirty:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">MyClass</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_add</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="go">14.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_add</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="go">array([ 5., 7., 9.])</span>
</pre></div>
</div>
<p><code class="code docutils literal"><span class="pre">MyClass.tf_reduce_sum</span></code> will only allow arguments that match the
shape <code class="code docutils literal"><span class="pre">[1,</span> <span class="pre">None]</span></code>; that is, rank 2 tensors whose first dimension
is <code class="code docutils literal"><span class="pre">5</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># shape is (3, 2), compatible with [3, None]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_reduce_sum</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">]])</span>
<span class="go">array([ 3., 5., 7.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># shape is (2, 1), not compatible with [3, None]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_reduce_sum</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">]])</span>
<span class="gt">Traceback (most recent call last):</span>
    <span class="o">...</span>
<span class="gr">ValueError</span>: <span class="n">Cannot feed value of shape (2, 1)...</span>
</pre></div>
</div>
<p>Autoflowed methods still work if the device context changes:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># set up a distributed execution environment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clusterdict</span> <span class="o">=</span> \
<span class="gp">... </span>    <span class="p">{</span> <span class="s1">&#39;worker&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;localhost:2224&#39;</span><span class="p">]</span>
<span class="gp">... </span>    <span class="p">,</span> <span class="s1">&#39;master&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;localhost:2225&#39;</span><span class="p">]</span>
<span class="gp">... </span>    <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ClusterSpec</span><span class="p">(</span><span class="n">clusterdict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">worker</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Server</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s1">&#39;worker&#39;</span><span class="p">,</span> <span class="n">task_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">worker</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">master</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Server</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s1">&#39;master&#39;</span><span class="p">,</span> <span class="n">task_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># change m&#39;s device context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># we&#39;re about to do weird things with op placement, and we</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># don&#39;t want it in the default graph where it can mess with</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># other doctests, so change m&#39;s tf_graph as well.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:worker/task:0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_session_target</span> <span class="o">=</span> <span class="n">master</span><span class="o">.</span><span class="n">target</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># autoflow</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_add</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">5.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_reduce_sum</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">],</span> <span class="p">[</span><span class="mf">7.</span><span class="p">,</span> <span class="mf">8.</span><span class="p">,</span> <span class="mf">9.</span><span class="p">]])</span>
<span class="go">array([  6., 15., 24.])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this headline">¶</a></h2>
<p>Jump to:</p>
<ul class="simple">
<li><a class="reference internal" href="#gptf.Model" title="gptf.Model"><code class="xref py py-class docutils literal"><span class="pre">gptf.Model</span></code></a></li>
<li><a class="reference internal" href="#gptf.GPModel" title="gptf.GPModel"><code class="xref py py-class docutils literal"><span class="pre">gptf.GPModel</span></code></a></li>
</ul>
<p>These abstract base classes implement models that can be optimised. Subclass
these and implement the abstract methods to implement new models. Both
<a class="reference internal" href="#gptf.Model" title="gptf.Model"><code class="xref py py-class docutils literal"><span class="pre">gptf.Model</span></code></a> and <a class="reference internal" href="#gptf.GPModel" title="gptf.GPModel"><code class="xref py py-class docutils literal"><span class="pre">gptf.GPModel</span></code></a> inherit from
<a class="reference internal" href="#gptf.Parameterized" title="gptf.Parameterized"><code class="xref py py-class docutils literal"><span class="pre">gptf.Parameterized</span></code></a>.
See <a class="reference internal" href="#gpr">GPR</a> for more information.</p>
<dl class="class">
<dt id="gptf.Model">
<em class="property">class </em><code class="descclassname">gptf.</code><code class="descname">Model</code><a class="reference internal" href="_modules/gptf/core/models.html#Model"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Model" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for models.</p>
<p>Inheriting classes must define <code class="code docutils literal"><span class="pre">.build_log_likelihood(self)</span></code>.</p>
<p><code class="code docutils literal"><span class="pre">Param</span></code> and <code class="code docutils literal"><span class="pre">Parameterized</span></code> objects that are children of the model
can be used in the tensorflow expression. Children on the model are
defined like so:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">overrides</span> <span class="k">import</span> <span class="n">overrides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf</span> <span class="k">import</span> <span class="n">Param</span><span class="p">,</span> <span class="n">ParamAttributes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="n">ParamAttributes</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>  <span class="c1"># create new Param child</span>
<span class="gp">...</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nd">@overrides</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">build_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="mi">3</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">tensor</span>  <span class="c1"># use Param in expression</span>
</pre></div>
</div>
<p>The <code class="code docutils literal"><span class="pre">.optimize</span></code> method can be used to optimize the parameters of the
model to minimise the likelihood. The loss function (the negative of
the sum of the likelihood and any priors) is cached in the WrappedTF
cache, and lazily recompiled when the cache is cleared, e.g. on
recompile.</p>
<dl class="method">
<dt id="gptf.Model.build_log_likelihood">
<code class="descname">build_log_likelihood</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#Model.build_log_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Model.build_log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds the log likelihood of the model w.r.t. the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs.</li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that, when run, calculates the log
likelihood of the model.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.Model.build_log_prior">
<code class="descname">build_log_prior</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#Model.build_log_prior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Model.build_log_prior" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="gptf.Model.compute_log_likelihood">
<code class="descname">compute_log_likelihood</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#Model.compute_log_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Model.compute_log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the likelihood of the model w.r.t. the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The log likelihood of the model.</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body">(np.ndarray)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.Model.compute_log_prior">
<code class="descname">compute_log_prior</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#Model.compute_log_prior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Model.compute_log_prior" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="gptf.Model.optimize">
<code class="descname">optimize</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>method='L-BFGS-B'</em>, <em>callback=None</em>, <em>maxiter=1000</em>, <em>**kw</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#Model.optimize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.Model.optimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Optimize the model by maximising the log likelihood.</p>
<p>Maximises the sum of the log likelihood given X &amp; Y and any
priors with respect to any free variables.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>np.ndarray | tf.Tensor</em>) &#8211; The training inputs.</li>
<li><strong>Y</strong> (<em>np.ndarray | tf.Tensor</em>) &#8211; The training outputs.</li>
<li><strong>method</strong> (<em>tf.train.Optimizer | str</em>) &#8211; The means by which to
optimise. If <code class="code docutils literal"><span class="pre">method</span></code> is a string, it will be passed as
the <code class="code docutils literal"><span class="pre">method</span></code> argument to the initialiser of
<code class="code docutils literal"><span class="pre">tf.contrib.opt.ScipyOptimizerInterface</span></code>. Else, it
will be treated as an instance of <code class="code docutils literal"><span class="pre">tf.train.Optimizer</span></code>
and its <code class="code docutils literal"><span class="pre">.minimize()</span></code> method will be used as the training
step.</li>
<li><strong>callback</strong> (<em>Callable[[np.ndarray], ...]</em>) &#8211; A function that will
be called at each optimization step with the current value
of the variable vector (a vector constructed by flattening
the free state of each free <code class="code docutils literal"><span class="pre">Param</span></code> and then concatenating
them in the order the <code class="code docutils literal"><span class="pre">Param</span></code>s are returned by <code class="code docutils literal"><span class="pre">.params</span></code>.</li>
<li><strong>maxiter</strong> (<em>int</em>) &#8211; The maximum number of iterations of the optimizer.</li>
<li><strong>**kw</strong> &#8211; Additional keyword arguments are passed through to the
optimizer.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">(scipy.OptimizeResult) The result of the optimisation.</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>Let&#8217;s construct a very simple model for demonstration
purposes. It has two (scalar) parameters, <code class="code docutils literal"><span class="pre">.a</span></code> and <code class="code docutils literal"><span class="pre">.b</span></code>,
which are constrained to be positive, and its likelihood is
<code class="code docutils literal"><span class="pre">10</span> <span class="pre">-</span> <span class="pre">a</span> <span class="pre">-</span> <span class="pre">b</span></code>, regardless of X and Y.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numbers</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">overrides</span> <span class="k">import</span> <span class="n">overrides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf</span> <span class="k">import</span> <span class="n">Param</span><span class="p">,</span> <span class="n">ParamAttributes</span><span class="p">,</span> <span class="n">transforms</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="n">ParamAttributes</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">)</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Exp</span><span class="p">(</span><span class="mf">0.</span><span class="p">))</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">Param</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Exp</span><span class="p">(</span><span class="mf">0.</span><span class="p">))</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nd">@overrides</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">build_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="mf">10.</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">tensor</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">tensor</span>
</pre></div>
</div>
<p>We won&#8217;t care about the values of X and Y.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mf">0.</span><span class="p">)</span>
</pre></div>
</div>
<p class="rubric">TensorFlow optimizers</p>
<p>We can optimise the parameters of the model using a TensorFlow
optimizer like so:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Example</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>  <span class="c1"># use None for X, Y</span>
<span class="go">message: &#39;Finished iterations.&#39;</span>
<span class="go">success: True</span>
<span class="go">      x: array([..., ...])</span>
</pre></div>
</div>
<p>After the optimisation, both parameters are optimised
towards 0, but are still positive. The constraints on the
parameters have been respected.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.a: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.a: 0.001</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.b: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.b: 0.001</span>
</pre></div>
</div>
<p>If we fix a parameter, it is not optimized:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="mf">5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">fixed</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
<span class="go">message: &#39;Finished iterations.&#39;</span>
<span class="go">success: True</span>
<span class="go">      x: array([...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.a: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.a: 0.001</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.b: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.b: 1.000</span>
</pre></div>
</div>
<p class="rubric">SciPy optimizers</p>
<p>We can optimise the parameters of the model using a SciPy
optimizer by provided a string value for <code class="code docutils literal"><span class="pre">method</span></code>:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Example</span><span class="p">(</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ftol</span><span class="o">=.</span><span class="mi">0001</span><span class="p">)</span>
<span class="go">message: &#39;SciPy optimizer completed successfully.&#39;</span>
<span class="go">success: True</span>
<span class="go">      x: array([..., ...])</span>
</pre></div>
</div>
<p>As for TensorFlow optimizers, after the optimisation both
parameters are optimised towards 0, but are still positive.
The constraints on the parameters have been respected.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.a: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.a: 0.000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.b: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.b: 0.000</span>
</pre></div>
</div>
<p>If we fix a parameter, it is not optimized:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="mf">5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">fixed</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ftol</span><span class="o">=.</span><span class="mi">0001</span><span class="p">)</span>
<span class="go">message: &#39;SciPy optimizer completed successfully.&#39;</span>
<span class="go">success: True</span>
<span class="go">      x: array([...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.a: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.a: 0.000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.b: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.b: 1.000</span>
</pre></div>
</div>
<p class="rubric">Miscellaneous</p>
<p>Optimisation still works, even with weird device contexts and
session targets.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># set up a distributed execution environment</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clusterdict</span> <span class="o">=</span> \
<span class="gp">... </span>    <span class="p">{</span> <span class="s1">&#39;worker&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;localhost:2226&#39;</span><span class="p">]</span>
<span class="gp">... </span>    <span class="p">,</span> <span class="s1">&#39;master&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;localhost:2227&#39;</span><span class="p">]</span>
<span class="gp">... </span>    <span class="p">}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spec</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">ClusterSpec</span><span class="p">(</span><span class="n">clusterdict</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">worker</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Server</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s1">&#39;worker&#39;</span><span class="p">,</span> <span class="n">task_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">worker</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">master</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Server</span><span class="p">(</span><span class="n">spec</span><span class="p">,</span> <span class="n">job_name</span><span class="o">=</span><span class="s1">&#39;master&#39;</span><span class="p">,</span> <span class="n">task_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># change m&#39;s device context</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># we&#39;re about to do weird things with op placement, and we</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># don&#39;t want it in the default graph where it can mess with</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># other doctests, so change m&#39;s tf_graph as well.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_device</span> <span class="o">=</span> <span class="s1">&#39;/job:worker/task:0&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">tf_session_target</span> <span class="o">=</span> <span class="n">master</span><span class="o">.</span><span class="n">target</span>
</pre></div>
</div>
<p>TensorFlow:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="mf">4.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
<span class="go">message: &#39;Finished iterations.&#39;</span>
<span class="go">success: True</span>
<span class="go">      x: array([...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.a: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.a: 0.001</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.b: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.b: 1.000</span>
</pre></div>
</div>
<p>SciPy:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">a</span> <span class="o">=</span> <span class="mf">4.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s1">&#39;L-BFGS-B&#39;</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ftol</span><span class="o">=.</span><span class="mi">0001</span><span class="p">)</span>
<span class="go">message: &#39;SciPy optimizer completed successfully.&#39;</span>
<span class="go">success: True</span>
<span class="go">      x: array([...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.a: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">a</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.a: 0.001</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;m.b: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asscalar</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">value</span><span class="p">)))</span>
<span class="go">m.b: 1.000</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="gptf.GPModel">
<em class="property">class </em><code class="descclassname">gptf.</code><code class="descname">GPModel</code><a class="reference internal" href="_modules/gptf/core/models.html#GPModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel" title="Permalink to this definition">¶</a></dt>
<dd><p>A base class for Guassian Process models.</p>
<p>A Gaussian process model is a model of the form</p>
<div class="math">
\[ \begin{align}\begin{aligned}θ ~ p(θ)\\f ~ GP(m(x), k(x, x'; θ))\\F = f(X)\\Y|F ~ p(Y|F)\end{aligned}\end{align} \]</div>
<p>Adds functionality to compile various predictions. Inheriting
classes must define <code class="code docutils literal"><span class="pre">.build_predict()</span></code>, which is then used by this
class&#8217;s methods to provide various predictions. The mean and
variance are pushed through the likelihood to obtain the means and
variances of held out data.</p>
<dl class="method">
<dt id="gptf.GPModel.build_posterior_mean_var">
<code class="descname">build_posterior_mean_var</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.build_posterior_mean_var"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.build_posterior_mean_var" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds an op for the mean and variance of the posterior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.GPModel.build_prior_mean_var">
<code class="descname">build_prior_mean_var</code><span class="sig-paren">(</span><em>test_points</em>, <em>num_latent</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.build_prior_mean_var"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.build_prior_mean_var" title="Permalink to this definition">¶</a></dt>
<dd><p>Builds an op for the mean and variance of the prior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the prior distribution(s). The shape should be
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>num_latent</strong> (<em>tf.int32</em>) &#8211; The number of latent functions of
the GP.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.GPModel.compute_posterior_mean_cov">
<code class="descname">compute_posterior_mean_cov</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.compute_posterior_mean_cov"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.compute_posterior_mean_cov" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the means and full covariance matrices.</p>
<p>This is just an autoflowed version of
<code class="code docutils literal"><span class="pre">.build_predict(X,</span> <span class="pre">Y,</span> <span class="pre">test_points,</span> <span class="pre">full_cov=True)</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>np.ndarray</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>np.ndarray</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>np.ndarray</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The means at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>), the full covriance
matri(x|ces) for the posterior distribution(s)
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(np.ndarray, np.ndarray)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.GPModel.compute_posterior_mean_var">
<code class="descname">compute_posterior_mean_var</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.compute_posterior_mean_var"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.compute_posterior_mean_var" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the means and variances of the posterior(s).</p>
<p>This is just an autoflowed version of
<code class="code docutils literal"><span class="pre">.build_posterior_mean_var(X,</span> <span class="pre">Y,</span> <span class="pre">test_points)</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>np.ndarray</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>np.ndarray</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>np.ndarray</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The means at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>), the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(np.ndarray, np.ndarray)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.GPModel.compute_posterior_samples">
<code class="descname">compute_posterior_samples</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em>, <em>num_samples</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.compute_posterior_samples"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.compute_posterior_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes samples from the posterior distribution(s).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>np.ndarray</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>np.ndarray</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>np.ndarray</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>num_samples</strong> (<em>int</em>) &#8211; The number of samples to take.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">An array of samples from the posterior
distributions, with shape <code class="code docutils literal"><span class="pre">[num_samples,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(np.ndarray)</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>For testing purposes, we create an example model whose
likelihood is always <code class="code docutils literal"><span class="pre">0</span></code> and whose <code class="code docutils literal"><span class="pre">.build_predict()</span></code>
returns mean <code class="code docutils literal"><span class="pre">0</span></code> and variance <code class="code docutils literal"><span class="pre">1</span></code> for every test point,
or an independent covariance matrix.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">overrides</span> <span class="k">import</span> <span class="n">overrides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf</span> <span class="k">import</span> <span class="n">ParamAttributes</span><span class="p">,</span> <span class="n">tfhacks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">GPModel</span><span class="p">,</span> <span class="n">ParamAttributes</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
<span class="gp">... </span>    <span class="nd">@property</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
<span class="gp">... </span>    <span class="nd">@dtype</span><span class="o">.</span><span class="n">setter</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">value</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nd">@overrides</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">build_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">NotImplemented</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nd">@overrides</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">build_prior_mean_var</span>\
<span class="gp">... </span>            <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_points</span><span class="p">,</span> <span class="n">num_latent</span><span class="p">,</span> <span class="n">full_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">NotImplemented</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nd">@overrides</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">build_posterior_mean_var</span>\
<span class="gp">... </span>            <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_points</span><span class="p">,</span> <span class="n">full_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">n</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">test_points</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">... </span>        <span class="n">num_latent</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">Y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="gp">... </span>        <span class="n">mu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">mu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_latent</span><span class="p">))</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="n">full_cov</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tfhacks</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>            <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_latent</span><span class="p">))</span>
<span class="gp">... </span>        <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="gp">... </span>            <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_latent</span><span class="p">))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">var</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Example</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">.</span><span class="mi">5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">.</span><span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">]])</span>
</pre></div>
</div>
<p>The shape of the returned array is <code class="code docutils literal"><span class="pre">(a,</span> <span class="pre">b,</span> <span class="pre">c)</span></code>, where <code class="code docutils literal"><span class="pre">a</span></code>
is the number of samples, <code class="code docutils literal"><span class="pre">b</span></code> is the number of test points
and <code class="code docutils literal"><span class="pre">c</span></code> is the number of latent functions.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">compute_posterior_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 4, 1)</span>
</pre></div>
</div>
<p><code class="code docutils literal"><span class="pre">.compute_posterior_samples()</span></code> respects the dtype of the tensors
returned by <code class="code docutils literal"><span class="pre">.build_predict()</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;float64&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">compute_posterior_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;float32&#39;)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gptf.GPModel.compute_prior_mean_cov">
<code class="descname">compute_prior_mean_cov</code><span class="sig-paren">(</span><em>test_points</em>, <em>num_latent</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.compute_prior_mean_cov"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.compute_prior_mean_cov" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the means and full covariance matrices.</p>
<p>This is just an autoflowed version of
<code class="code docutils literal"><span class="pre">.build_prior_mean_var(test_points,</span> <span class="pre">num_latent,</span> <span class="pre">True)</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test_points</strong> (<em>np.ndarray</em>) &#8211; The points from the sample
space for which to predict means and variances
of the prior distribution(s). The shape should be
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>num_latent</strong> (<em>int</em>) &#8211; The number of latent functions of the GP.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The means at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>), the full covariance
matri(x|ces) for the prior distribution(s) (shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(np.ndarray, np.ndarray)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.GPModel.compute_prior_mean_var">
<code class="descname">compute_prior_mean_var</code><span class="sig-paren">(</span><em>test_points</em>, <em>num_latent</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.compute_prior_mean_var"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.compute_prior_mean_var" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the means and variances of the prior(s).</p>
<p>This is just an autoflowed version of
<code class="code docutils literal"><span class="pre">.build_prior_mean_var(test_points,</span> <span class="pre">num_latent)</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test_points</strong> (<em>np.ndarray</em>) &#8211; The points from the sample
space for which to predict means and variances
of the prior distribution(s). The shape should be
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>num_latent</strong> (<em>int</em>) &#8211; The number of latent functions of the GP.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">the mean at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>), the variances at the test
points (shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>).</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(np.ndarray, np.ndarray)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="gptf.GPModel.compute_prior_samples">
<code class="descname">compute_prior_samples</code><span class="sig-paren">(</span><em>test_points</em>, <em>num_latent</em>, <em>num_samples</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.compute_prior_samples"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.compute_prior_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes samples from the prior distribution(s).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test_points</strong> (<em>np.ndarray</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>num_latent</strong> (<em>int</em>) &#8211; The number of latent functions of the GP.</li>
<li><strong>num_samples</strong> (<em>int</em>) &#8211; The number of samples to take.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">An array of samples from the prior
distributions, with shape <code class="code docutils literal"><span class="pre">[num_samples,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(np.ndarray)</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>For testing purposes, we create an example model whose
likelihood is always <code class="code docutils literal"><span class="pre">0</span></code> and whose <code class="code docutils literal"><span class="pre">.build_predict()</span></code>
returns mean <code class="code docutils literal"><span class="pre">0</span></code> and variance <code class="code docutils literal"><span class="pre">1</span></code> for every test point,
or an independent covariance matrix.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">overrides</span> <span class="k">import</span> <span class="n">overrides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf</span> <span class="k">import</span> <span class="n">ParamAttributes</span><span class="p">,</span> <span class="n">tfhacks</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Example</span><span class="p">(</span><span class="n">GPModel</span><span class="p">,</span> <span class="n">ParamAttributes</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
<span class="gp">... </span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
<span class="gp">... </span>    <span class="nd">@property</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>
<span class="gp">... </span>    <span class="nd">@dtype</span><span class="o">.</span><span class="n">setter</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">clear_cache</span><span class="p">()</span>
<span class="gp">... </span>        <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">value</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nd">@overrides</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">build_log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">NotImplemented</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nd">@overrides</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">build_prior_mean_var</span>\
<span class="gp">... </span>            <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_points</span><span class="p">,</span> <span class="n">num_latent</span><span class="p">,</span> <span class="n">full_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="gp">... </span>        <span class="n">n</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">test_points</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">... </span>        <span class="n">mu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="gp">... </span>        <span class="n">mu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_latent</span><span class="p">))</span>
<span class="gp">... </span>        <span class="k">if</span> <span class="n">full_cov</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">tfhacks</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">... </span>            <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_latent</span><span class="p">))</span>
<span class="gp">... </span>        <span class="k">else</span><span class="p">:</span>
<span class="gp">... </span>            <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="gp">... </span>            <span class="n">var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">var</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_latent</span><span class="p">))</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">var</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nd">@overrides</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">build_posterior_mean_var</span>\
<span class="gp">... </span>            <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_points</span><span class="p">,</span> <span class="n">full_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="gp">... </span>        <span class="bp">NotImplemented</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">Example</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>  <span class="c1"># ignore the likelihood</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.</span><span class="p">]])</span>
</pre></div>
</div>
<p>The shape of the returned array is <code class="code docutils literal"><span class="pre">(a,</span> <span class="pre">b,</span> <span class="pre">c)</span></code>, where <code class="code docutils literal"><span class="pre">a</span></code>
is the number of samples, <code class="code docutils literal"><span class="pre">b</span></code> is the number of test points
and <code class="code docutils literal"><span class="pre">c</span></code> is the number of latent functions.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">compute_prior_samples</span><span class="p">(</span><span class="n">test_points</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(2, 4, 1)</span>
</pre></div>
</div>
<p><code class="code docutils literal"><span class="pre">.compute_prior_samples()</span></code> respects the dtype of the tensors
returned by <code class="code docutils literal"><span class="pre">.build_predict()</span></code>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;float64&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">compute_prior_samples</span><span class="p">(</span><span class="n">test_points</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">samples</span><span class="o">.</span><span class="n">dtype</span>
<span class="go">dtype(&#39;float32&#39;)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="gptf.GPModel.predict_density">
<code class="descname">predict_density</code><span class="sig-paren">(</span><em>test_points</em>, <em>test_values</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.predict_density"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.predict_density" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the (log) density of the test values at the test points.</p>
</dd></dl>

<dl class="method">
<dt id="gptf.GPModel.predict_y">
<code class="descname">predict_y</code><span class="sig-paren">(</span><em>test_points</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/models.html#GPModel.predict_y"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#gptf.GPModel.predict_y" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the mean and variance of held-out data.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="public-core-modules">
<h2>Public core modules<a class="headerlink" href="#public-core-modules" title="Permalink to this headline">¶</a></h2>
<p>The following core modules are part of the public API, and are available
under <code class="code docutils literal"><span class="pre">gptf.&lt;module</span> <span class="pre">name&gt;</span></code> as well as <code class="code docutils literal"><span class="pre">gptf.core.&lt;module</span> <span class="pre">name&gt;</span></code>, e.g.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">gptf</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf.core</span> <span class="k">import</span> <span class="n">kernels</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gptf</span><span class="o">.</span><span class="n">kernels</span> <span class="ow">is</span> <span class="n">kernels</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="section" id="densities">
<h3>densities<a class="headerlink" href="#densities" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">bernoulli</code><span class="sig-paren">(</span><em>p</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#bernoulli"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">beta</code><span class="sig-paren">(</span><em>alpha</em>, <em>beta</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#beta"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">exponential</code><span class="sig-paren">(</span><em>lamb</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#exponential"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">gamma</code><span class="sig-paren">(</span><em>shape</em>, <em>scale</em>, <em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#gamma"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">gaussian</code><span class="sig-paren">(</span><em>x</em>, <em>mu</em>, <em>var</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#gaussian"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">laplace</code><span class="sig-paren">(</span><em>mu</em>, <em>sigma</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#laplace"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">lognormal</code><span class="sig-paren">(</span><em>x</em>, <em>mu</em>, <em>var</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#lognormal"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">multivariate_normal</code><span class="sig-paren">(</span><em>x</em>, <em>mu</em>, <em>L</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#multivariate_normal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>L is the Cholesky decomposition of the covariance.</p>
<p>x and mu are either vectors (ndim=1) or matrices. In the matrix case, we
assume independence over the <em>columns</em>: the number of rows must match the
size of L.</p>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">poisson</code><span class="sig-paren">(</span><em>lamb</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#poisson"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">student_t</code><span class="sig-paren">(</span><em>x</em>, <em>mean</em>, <em>scale</em>, <em>deg_free</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#student_t"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</div>
<div class="section" id="transforms">
<h3>transforms<a class="headerlink" href="#transforms" title="Permalink to this headline">¶</a></h3>
<p>Provides a number of transforms that can be used to constrain <code class="code docutils literal"><span class="pre">Param</span></code>s.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.transforms.</code><code class="descname">Exp</code><span class="sig-paren">(</span><em>lower=1e-06</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/transforms.html#Exp"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>An exponential transform.</p>
<p>value = exp(free_state) + lower</p>
<dl class="method">
<dt>
<code class="descname">np_backward</code><span class="sig-paren">(</span><em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/transforms.html#Exp.np_backward"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Map from the variable to the free space using NumPy.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">tf_forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/transforms.html#Exp.tf_forward"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Map from the free space to the variable space using TensorFlow.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.transforms.</code><code class="descname">Identity</code><a class="reference internal" href="_modules/gptf/core/transforms.html#Identity"><span class="viewcode-link">[source]</span></a></dt>
<dd><dl class="staticmethod">
<dt>
<em class="property">static </em><code class="descname">np_backward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/transforms.html#Identity.np_backward"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Map from the variable to the free space using NumPy.</p>
</dd></dl>

<dl class="staticmethod">
<dt>
<em class="property">static </em><code class="descname">tf_forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/transforms.html#Identity.tf_forward"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Map from the free space to the variable space using TensorFlow.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.transforms.</code><code class="descname">Transform</code><a class="reference internal" href="_modules/gptf/core/transforms.html#Transform"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>A transform, used to constrain the optimisation of a <code class="code docutils literal"><span class="pre">Param</span></code>.</p>
<p>NB: Unless otherwise stated, attributes of transforms are read-only
and should be treated as such. If you wish to change the transform
of a <code class="code docutils literal"><span class="pre">Param</span></code>, assign a <em>new</em> <code class="code docutils literal"><span class="pre">Transform</span></code> to its <code class="code docutils literal"><span class="pre">.transform</span></code> attribute.</p>
<dl class="method">
<dt>
<code class="descname">np_backward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/transforms.html#Transform.np_backward"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Map from the variable to the free space using NumPy.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">tf_forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/transforms.html#Transform.tf_forward"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Map from the free space to the variable space using TensorFlow.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="kernels">
<h3>kernels<a class="headerlink" href="#kernels" title="Permalink to this headline">¶</a></h3>
<p>All classes in this module inherit from <a class="reference internal" href="#gptf.Parameterized" title="gptf.Parameterized"><code class="xref py py-class docutils literal"><span class="pre">gptf.Parameterized</span></code></a>.</p>
<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">bernoulli</code><span class="sig-paren">(</span><em>p</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#bernoulli"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">beta</code><span class="sig-paren">(</span><em>alpha</em>, <em>beta</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#beta"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">exponential</code><span class="sig-paren">(</span><em>lamb</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#exponential"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">gamma</code><span class="sig-paren">(</span><em>shape</em>, <em>scale</em>, <em>x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#gamma"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">gaussian</code><span class="sig-paren">(</span><em>x</em>, <em>mu</em>, <em>var</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#gaussian"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">laplace</code><span class="sig-paren">(</span><em>mu</em>, <em>sigma</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#laplace"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">lognormal</code><span class="sig-paren">(</span><em>x</em>, <em>mu</em>, <em>var</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#lognormal"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">multivariate_normal</code><span class="sig-paren">(</span><em>x</em>, <em>mu</em>, <em>L</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#multivariate_normal"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>L is the Cholesky decomposition of the covariance.</p>
<p>x and mu are either vectors (ndim=1) or matrices. In the matrix case, we
assume independence over the <em>columns</em>: the number of rows must match the
size of L.</p>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">poisson</code><span class="sig-paren">(</span><em>lamb</em>, <em>y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#poisson"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.core.densities.</code><code class="descname">student_t</code><span class="sig-paren">(</span><em>x</em>, <em>mean</em>, <em>scale</em>, <em>deg_free</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/densities.html#student_t"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</div>
<div class="section" id="likelihoods">
<h3>likelihoods<a class="headerlink" href="#likelihoods" title="Permalink to this headline">¶</a></h3>
<p>All classes in this module inherit from <a class="reference internal" href="#gptf.Parameterized" title="gptf.Parameterized"><code class="xref py py-class docutils literal"><span class="pre">gptf.Parameterized</span></code></a>.</p>
<p>Provides facilities for calculating likelihoods, densities etc.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.likelihoods.</code><code class="descname">Gaussian</code><span class="sig-paren">(</span><em>variance=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Gaussian"><span class="viewcode-link">[source]</span></a></dt>
<dd><dl class="method">
<dt>
<code class="descname">conditional_mean</code><span class="sig-paren">(</span><em>F</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Gaussian.conditional_mean"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Computes the mean of the data given values of the latent func.</p>
<p>If this object represents <span class="math">\(p(y|f)\)</span>, then this method
computes</p>
<div class="math">
\[\int y p(y|f) dy\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>F</strong> (<em>tf.Tensor</em>) &#8211; Proposed values for the latent function.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The mean of the data given the value of the
latent function.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">(tf.Tensor)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">conditional_variance</code><span class="sig-paren">(</span><em>F</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Gaussian.conditional_variance"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Computes the variance of the data given values of the latent func.</p>
<p>If this object represents <span class="math">\(p(y|f)\)</span>, then this method
computes</p>
<div class="math">
\[\int y^2 p(y|f) dy - (\int y p(y|f) dy)^2\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>F</strong> (<em>tf.Tensor</em>) &#8211; Proposed values for the latent function.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The variance of the data given the value of the
latent function.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">(tf.Tensor)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">logp</code><span class="sig-paren">(</span><em>F</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Gaussian.logp"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The log density of the data given the function values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>F</strong> (<em>tf.Tensor</em>) &#8211; A set of proposed function values.</li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The data.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The log density of the data; <code class="code docutils literal"><span class="pre">p(Y|F)</span></code>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_density</code><span class="sig-paren">(</span><em>mu_F</em>, <em>var_F</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Gaussian.predict_density"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The (log) density of Y given a mean &amp; variance of the latent func.</p>
<p>if <span class="math">\(q(f) = N(mu_F, var_F)\)</span> and this object represents
<span class="math">\(p(y|f)\)</span>,
then this method computes the predictive density</p>
<div class="math">
\[\int p(y=Y|f) q(f) df\]</div>
<p>Here, we implement a Gauss-Hermite quadrature routine, but some
likelihoods (e.g. Gaussian, Poisson) will implement specific cases.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_mean_and_var</code><span class="sig-paren">(</span><em>mu_F</em>, <em>var_F</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Gaussian.predict_mean_and_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The mean &amp; variance of Y given a mean &amp; variance of the latent func.</p>
<p>if <span class="math">\(q(f) = N(mu_F, var_F)\)</span> and this object represents
<span class="math">\(p(y|f)\)</span>,
then this method computes the predictive mean</p>
<div class="math">
\[\int\int y p(y|f) q(f) df dy\]</div>
<p>and the predictive variance</p>
<div class="math">
\[\int\int y^2 p(y|f) q(f) df dy
- (\int\int y p(y|f) q(f) df dy)^2\]</div>
<p>Here, we implement a Gauss-Hermite quadrature routine, but some
likelihoods (e.g. Gaussian) will implement specific cases.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">variational_expectations</code><span class="sig-paren">(</span><em>mu_F</em>, <em>var_F</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Gaussian.variational_expectations"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Compute the expected log density of the data.</p>
<p>if <span class="math">\(q(f) = N(mu_F, var_F)\)</span> and this object represents
<span class="math">\(p(y|f)\)</span>,
then this method computes the predictive density</p>
<div class="math">
\[\int (\log p(y|f)) q(f) df\]</div>
<p>Here, we implement a Gauss-Hermite quadrature routine, but some
likelihoods (e.g. Gaussian, Poisson) will implement specific cases.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.likelihoods.</code><code class="descname">Likelihood</code><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Likelihood"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Abstract base class for likelihoods.</p>
<p>Inheriting classes must implement <code class="code docutils literal"><span class="pre">.logp()</span></code>, <code class="code docutils literal"><span class="pre">.conditional_mean()</span></code>
and <code class="code docutils literal"><span class="pre">.conditional_variance()</span></code>.</p>
<dl class="method">
<dt>
<code class="descname">conditional_mean</code><span class="sig-paren">(</span><em>F</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Likelihood.conditional_mean"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Computes the mean of the data given values of the latent func.</p>
<p>If this object represents <span class="math">\(p(y|f)\)</span>, then this method
computes</p>
<div class="math">
\[\int y p(y|f) dy\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>F</strong> (<em>tf.Tensor</em>) &#8211; Proposed values for the latent function.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The mean of the data given the value of the
latent function.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">(tf.Tensor)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">conditional_variance</code><span class="sig-paren">(</span><em>F</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Likelihood.conditional_variance"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Computes the variance of the data given values of the latent func.</p>
<p>If this object represents <span class="math">\(p(y|f)\)</span>, then this method
computes</p>
<div class="math">
\[\int y^2 p(y|f) dy - (\int y p(y|f) dy)^2\]</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>F</strong> (<em>tf.Tensor</em>) &#8211; Proposed values for the latent function.</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">The variance of the data given the value of the
latent function.</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body">(tf.Tensor)</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">logp</code><span class="sig-paren">(</span><em>F</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Likelihood.logp"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The log density of the data given the function values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>F</strong> (<em>tf.Tensor</em>) &#8211; A set of proposed function values.</li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The data.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The log density of the data; <code class="code docutils literal"><span class="pre">p(Y|F)</span></code>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_density</code><span class="sig-paren">(</span><em>mu_F</em>, <em>var_F</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Likelihood.predict_density"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The (log) density of Y given a mean &amp; variance of the latent func.</p>
<p>if <span class="math">\(q(f) = N(mu_F, var_F)\)</span> and this object represents
<span class="math">\(p(y|f)\)</span>,
then this method computes the predictive density</p>
<div class="math">
\[\int p(y=Y|f) q(f) df\]</div>
<p>Here, we implement a Gauss-Hermite quadrature routine, but some
likelihoods (e.g. Gaussian, Poisson) will implement specific cases.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">predict_mean_and_var</code><span class="sig-paren">(</span><em>mu_F</em>, <em>var_F</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Likelihood.predict_mean_and_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The mean &amp; variance of Y given a mean &amp; variance of the latent func.</p>
<p>if <span class="math">\(q(f) = N(mu_F, var_F)\)</span> and this object represents
<span class="math">\(p(y|f)\)</span>,
then this method computes the predictive mean</p>
<div class="math">
\[\int\int y p(y|f) q(f) df dy\]</div>
<p>and the predictive variance</p>
<div class="math">
\[\int\int y^2 p(y|f) q(f) df dy
- (\int\int y p(y|f) q(f) df dy)^2\]</div>
<p>Here, we implement a Gauss-Hermite quadrature routine, but some
likelihoods (e.g. Gaussian) will implement specific cases.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">variational_expectations</code><span class="sig-paren">(</span><em>mu_F</em>, <em>var_F</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/likelihoods.html#Likelihood.variational_expectations"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Compute the expected log density of the data.</p>
<p>if <span class="math">\(q(f) = N(mu_F, var_F)\)</span> and this object represents
<span class="math">\(p(y|f)\)</span>,
then this method computes the predictive density</p>
<div class="math">
\[\int (\log p(y|f)) q(f) df\]</div>
<p>Here, we implement a Gauss-Hermite quadrature routine, but some
likelihoods (e.g. Gaussian, Poisson) will implement specific cases.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="meanfunctions">
<h3>meanfunctions<a class="headerlink" href="#meanfunctions" title="Permalink to this headline">¶</a></h3>
<p>All classes in this module inherit from <a class="reference internal" href="#gptf.Parameterized" title="gptf.Parameterized"><code class="xref py py-class docutils literal"><span class="pre">gptf.Parameterized</span></code></a>.</p>
<p>Provides mean functions.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.meanfunctions.</code><code class="descname">Absolute</code><span class="sig-paren">(</span><em>function</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#Absolute"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The absolute value of a mean function.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.meanfunctions.</code><code class="descname">Additive</code><span class="sig-paren">(</span><em>*functions</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#Additive"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The addition of mean functions.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.meanfunctions.</code><code class="descname">Constant</code><span class="sig-paren">(</span><em>c=array([0])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#Constant"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>y_i = c,,</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.meanfunctions.</code><code class="descname">Divisive</code><span class="sig-paren">(</span><em>numerator</em>, <em>denominator</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#Divisive"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The division of mean functions.</p>
<p><code class="code docutils literal"><span class="pre">Divisive(a,</span> <span class="pre">b)(X)</span></code> returns <code class="code docutils literal"><span class="pre">a(X)</span> <span class="pre">/</span> <span class="pre">b(X)</span></code>.</p>
<dl class="method">
<dt>
<code class="descname">clone</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#Divisive.clone"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.meanfunctions.</code><code class="descname">Linear</code><span class="sig-paren">(</span><em>A=array([[ 1.]])</em>, <em>b=array([ 0.])</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#Linear"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>y_i = A x_i + b</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.meanfunctions.</code><code class="descname">MeanFunction</code><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#MeanFunction"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Abstract base class for mean functions.</p>
<p>Inheriting classes must define <code class="code docutils literal"><span class="pre">.__call__()</span></code>.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">Ones</span><span class="p">(</span><span class="n">MeanFunction</span><span class="p">,</span> <span class="n">ParamAttributes</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nd">@tf_method</span><span class="p">()</span>
<span class="gp">... </span>    <span class="nd">@overrides</span>
<span class="gp">... </span>    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">InteractiveSession</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Ones</span><span class="p">()(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="go">array([ 1.,  1.,  1.,  1.])</span>
</pre></div>
</div>
<p>You can do maths with mean functions! Addition and subtraction:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">threes</span> <span class="o">=</span> <span class="n">Ones</span><span class="p">()</span> <span class="o">+</span> <span class="n">Ones</span><span class="p">()</span> <span class="o">+</span> <span class="n">Ones</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">threes</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="go">array([ 3.,  3.,  3.,  3.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">threes</span> <span class="o">-</span> <span class="n">Ones</span><span class="p">())(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="go">array([ 2.,  2.,  2.,  2.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="o">-</span><span class="n">threes</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="go">array([-3., -3., -3., -3.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">abs</span><span class="p">(</span><span class="o">-</span><span class="n">threes</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="go">array([ 3.,  3.,  3.,  3.])</span>
</pre></div>
</div>
<p>Multiplication and division:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">threes</span> <span class="o">*</span> <span class="n">threes</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="go">array([ 9., 9., 9., 9.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">Ones</span><span class="p">()</span> <span class="o">/</span> <span class="n">threes</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="go">array([ 0.333, 0.333, 0.333, 0.333])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">threes</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># this works as a special case</span>
<span class="go">array([ 0.333, 0.333, 0.333, 0.333])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">threes</span> <span class="o">*</span> <span class="n">threes</span> <span class="o">/</span> <span class="n">threes</span> <span class="o">*</span> <span class="n">threes</span><span class="p">)(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="go">array([ 9., 9., 9., 9.])</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sess</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.meanfunctions.</code><code class="descname">Multiplicative</code><span class="sig-paren">(</span><em>*functions</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#Multiplicative"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The multiplication of mean functions.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.meanfunctions.</code><code class="descname">Negative</code><span class="sig-paren">(</span><em>function</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#Negative"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The negative of a mean function.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.core.meanfunctions.</code><code class="descname">Zero</code><span class="sig-paren">(</span><em>num_latent_functions=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/core/meanfunctions.html#Zero"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

</div>
</div>
<div class="section" id="gpr">
<h2>GPR<a class="headerlink" href="#gpr" title="Permalink to this headline">¶</a></h2>
<p>For example code that plays with the classes in this module, see the
<a class="reference external" href="https://github.com/ICL-SML/gptf/blob/master/notebooks/Gaussian_process_regression.ipynb">GPR notebook</a>.</p>
<p>GP regression with Gaussian noise.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.gpr.</code><code class="descname">GPR</code><span class="sig-paren">(</span><em>kernel</em>, <em>meanfunction=&lt;gptf.core.meanfunctions.Zero object</em>, <em>fallback_name unnamed</em>, <em>id 0x7fa38d42b588&gt;</em>, <em>noise_variance=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/gpr.html#GPR"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Gaussian process regression with Gaussian noise.</p>
<dl class="attribute">
<dt id="gptf.gpr.GPR.kernel">
<code class="descname">kernel</code><a class="headerlink" href="#gptf.gpr.GPR.kernel" title="Permalink to this definition">¶</a></dt>
<dd><p><em>gptf.kernels.Kernel</em> &#8211; The kernel of the GP.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.gpr.GPR.meanfunc">
<code class="descname">meanfunc</code><a class="headerlink" href="#gptf.gpr.GPR.meanfunc" title="Permalink to this definition">¶</a></dt>
<dd><p><em>gptf.meanfunctions.MeanFunctions</em> &#8211; The mean function
of the GP.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.gpr.GPR.likelihood">
<code class="descname">likelihood</code><a class="headerlink" href="#gptf.gpr.GPR.likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p><em>gptf.likelihoods.Gaussian</em> &#8211; The likelihood of the GP</p>
</dd></dl>

<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">gptf</span> <span class="k">import</span> <span class="n">kernels</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span> <span class="o">=</span> <span class="n">GPR</span><span class="p">(</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBF</span><span class="p">(</span><span class="n">variance</span><span class="o">=</span><span class="mf">10.</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span><span class="o">.</span><span class="n">fallback_name</span> <span class="o">=</span> <span class="s2">&quot;gp&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="o">.</span><span class="mi">25</span> <span class="c1"># reduce noise</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;plain&#39;</span><span class="p">))</span>
<span class="go">Parameterized object gp</span>

<span class="go">Params:</span>
<span class="go">    name                   | value  | transform | prior</span>
<span class="go">    -----------------------+--------+-----------+------</span>
<span class="go">    gp.kernel.lengthscales | 1.000  | +ve (Exp) | nyi</span>
<span class="go">    gp.kernel.variance     | 10.000 | +ve (Exp) | nyi</span>
<span class="go">    gp.likelihood.variance | 0.250  | +ve (Exp) | nyi</span>
</pre></div>
</div>
<p>To generate some sample training outputs, we&#8217;ll compute a
sample from the prior with one latent function at our
training inputs.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># 500 unique 1d points</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="n">gp</span><span class="o">.</span><span class="n">compute_prior_samples</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
<p>Then we&#8217;ll add some noise:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p>Then we&#8217;ll mess with the value of the parameters. When
we optimise the model, they should return to something close
to their original state.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="mf">5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">lengthscales</span> <span class="o">=</span> <span class="mf">5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="mf">5.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gp</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="go">message: &#39;SciPy optimizer completed successfully.&#39;</span>
<span class="go">success: True</span>
<span class="go">      x: array([...,...,...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">vaguely_close_to</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">v</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">value</span>
<span class="gp">... </span>    <span class="k">return</span> <span class="nb">abs</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">v</span><span class="o">*.</span><span class="mi">25</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">b</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vaguely_close_to</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">lengthscales</span><span class="p">,</span> <span class="mf">1.</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vaguely_close_to</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span> <span class="mf">10.</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">vaguely_close_to</span><span class="p">(</span><span class="n">gp</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span> <span class="o">.</span><span class="mi">25</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<dl class="method">
<dt>
<code class="descname">build_log_likelihood</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/gpr.html#GPR.build_log_likelihood"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds the log likelihood of the model w.r.t. the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs.</li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that, when run, calculates the log
likelihood of the model.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">build_posterior_mean_var</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/gpr.html#GPR.build_posterior_mean_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds an op for the mean and variance of the posterior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">build_prior_mean_var</code><span class="sig-paren">(</span><em>test_points</em>, <em>num_latent</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/gpr.html#GPR.build_prior_mean_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds an op for the mean and variance of the prior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the prior distribution(s). The shape should be
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>num_latent</strong> (<em>tf.int32</em>) &#8211; The number of latent functions of
the GP.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="distributed">
<h2>Distributed<a class="headerlink" href="#distributed" title="Permalink to this headline">¶</a></h2>
<p>For example code that plays with the classes in this module, see the
<a class="reference external" href="https://github.com/ICL-SML/gptf/blob/master/notebooks/DistributedGaussianprocessmodels.ipynb">distributed GP models</a> and the <a class="reference external" href="https://github.com/ICL-SML/gptf/blob/master/notebooks/Distributedcomputation.ipynb">distributed computation</a> notebooks.</p>
<p>Provides classes for Robust Bayesian Committee Machines.</p>
<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.distributed.</code><code class="descname">BCMReduction</code><span class="sig-paren">(</span><em>children</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#BCMReduction"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Combines the predictions of its children using the BCM model.</p>
<p>In the Bayesian Committee Machine (BCM) model, the variance of the
posterior distribution is the harmonic mean of the posterior
variances of the child experts, with a correction term based on
the prior variance. The mean of the posterior is a weighted sum of
the means of the child experts multiplied by the posterior variance.</p>
<div class="math">
\[\begin{split}σ^{-2}_{BCM} &amp;= (\sum_{k=1}^{M} σ^{-2}_k)
              + (1 - M) σ^{-2}_{\star\star} \\
μ_{BCM} &amp;= σ^2_{BCM} \sum_{k=1}^{M} μ_k σ^{-2}_k\end{split}\]</div>
<p>where <span class="math">\(μ_{BCM}\)</span> and <span class="math">\(σ^2_{BCM}\)</span> are the final posterior
mean and variance, <span class="math">\(M\)</span> is the number of child experts,
<span class="math">\(σ^{-2}_{\star\star}\)</span> is the prior precision and
<span class="math">\(μ_k\)</span> and <span class="math">\(σ^2_k\)</span> are the posterior mean and variance
for the <span class="math">\(k\)</span>th child.</p>
<p>Attributes: See <code class="code docutils literal"><span class="pre">GPModel</span></code> and <code class="code docutils literal"><span class="pre">ParamList</span></code>.</p>
<dl class="method">
<dt>
<code class="descname">build_posterior_mean_var</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#BCMReduction.build_posterior_mean_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds an op for the mean and variance of the posterior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.distributed.</code><code class="descname">PoEReduction</code><span class="sig-paren">(</span><em>children</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#PoEReduction"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Combines the predictions of its children using the PoE model.</p>
<p>In the Product of Experts (PoE) model, the variance of the
posterior distribution is the harmonic mean of the posterior
variances of the child experts. The mean of the posterior is a
weighted sum of the means of the child experts multiplied by
the posterior variance.</p>
<div class="math">
\[\begin{split}σ^{-2}_{PoE} &amp;= \sum_{k=1}^{M} σ^{-2}_k \\
μ_{PoE} &amp;= σ^2_{PoE} \sum_{k=1}^{M} μ_k σ^{-2}_k\end{split}\]</div>
<p>where <span class="math">\(μ_{PoE}\)</span> and <span class="math">\(σ^2_{PoE}\)</span> are the final posterior
mean and variance, <span class="math">\(M\)</span> is the number of child experts and
<span class="math">\(μ_k\)</span> and <span class="math">\(σ^2_k\)</span> are the posterior mean and variance
for the <span class="math">\(k\)</span>th child.</p>
<p>Attributes: See <code class="xref py py-obj docutils literal"><span class="pre">GPModel</span></code> and <code class="xref py py-obj docutils literal"><span class="pre">ParamList</span></code>.</p>
<dl class="method">
<dt>
<code class="descname">build_posterior_mean_var</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#PoEReduction.build_posterior_mean_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds an op for the mean and variance of the posterior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.distributed.</code><code class="descname">PriorDivisorReduction</code><span class="sig-paren">(</span><em>child</em>, <em>weightfunction</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#PriorDivisorReduction"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Divides by the prior in proportion to the weight.</p>
<p>This is mostly a convenience cljkass for constructing a hierarchical
rBCM. It delegates the <code class="code docutils literal"><span class="pre">.build_log_likelihood()</span></code> and
<code class="code docutils literal"><span class="pre">.build_prior_mean_var()</span></code> methods to the child expert, and corrects
the posterior mean and variance with a prior division term.</p>
<dl class="attribute">
<dt id="gptf.distributed.PriorDivisorReduction.child">
<code class="descname">child</code><a class="headerlink" href="#gptf.distributed.PriorDivisorReduction.child" title="Permalink to this definition">¶</a></dt>
<dd><p><em>GPModel</em> &#8211; The expert to correct the opinion of.</p>
</dd></dl>

<dl class="attribute">
<dt id="gptf.distributed.PriorDivisorReduction.weightfunction">
<code class="descname">weightfunction</code><a class="headerlink" href="#gptf.distributed.PriorDivisorReduction.weightfunction" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Callable[[Sequence[GPModel], tf.Tensor, tf.Tensor, tf.Tensor], Tuple[tf.Tensor]]</em> &#8211; A function used to calculate the weight of the expert.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">build_log_likelihood</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#PriorDivisorReduction.build_log_likelihood"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds the log likelihood of the model w.r.t. the data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs.</li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that, when run, calculates the log
likelihood of the model.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">build_posterior_mean_var</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#PriorDivisorReduction.build_posterior_mean_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds an op for the mean and variance of the posterior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">build_prior_mean_var</code><span class="sig-paren">(</span><em>test_points</em>, <em>num_latent</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#PriorDivisorReduction.build_prior_mean_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds an op for the mean and variance of the prior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the prior distribution(s). The shape should be
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>num_latent</strong> (<em>tf.int32</em>) &#8211; The number of latent functions of
the GP.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.distributed.</code><code class="descname">Reduction</code><span class="sig-paren">(</span><em>initial_values=()</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#Reduction"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Common code for distributed GP reductions.</p>
<dl class="method">
<dt>
<code class="descname">build_log_likelihood</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#Reduction.build_log_likelihood"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The sum of the log likelihoods of the children.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="descname">build_prior_mean_var</code><span class="sig-paren">(</span><em>test_points</em>, <em>num_latent</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#Reduction.build_prior_mean_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The arithetic mean of the prior mean / variance of the chilren.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.distributed.</code><code class="descname">cao_fleet_weights</code><span class="sig-paren">(</span><em>experts</em>, <em>X</em>, <em>Y</em>, <em>points</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#cao_fleet_weights"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>The predictive power of the experts at the points.</p>
<p>The predictive power is calculated as</p>
<div class="math">
\[β_k(x_\star)=\frac{1}{2} (\ln (σ^\star_k)^2 - \ln σ^{-2}_k(x_\star))\]</div>
<p>where <span class="math">\(β_k(x_\star)\)</span> is the predictive power of the
<span class="math">\(k`th expert at the point :math:`x_\star\)</span>,
<span class="math">\((σ^\star_k)^2\)</span> is the prior variance of the <span class="math">\(k\)</span>th
expert and <span class="math">\(σ^{-2}_k(x_\star)\)</span> is the posterior variance
of the <span class="math">\(k\)</span>th expert at the point <span class="math">\(x_\star\)</span>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>experts</strong> (<em>Sequence[GPModel]</em>) &#8211; the experts to calculate
the weights of.</li>
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; the training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; the training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code>.</li>
<li><strong>points</strong> (<em>tf.Tensor</em>) &#8211; the points at which to calculate the
weights of the model, shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The weights of the experts at the
points. Each tensor has shape <code class="code docutils literal"><span class="pre">(num_points,</span> <span class="pre">num_latent)</span></code>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(Tuple[tf.Tensor])</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.distributed.</code><code class="descname">chunks</code><span class="sig-paren">(</span><em>n</em>, <em>iterable</em>, <em>padvalue=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#chunks"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Iterator for equal-sized chunks of an iterable.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n</strong> (<em>int</em>) &#8211; The size of each chunk.</li>
<li><strong>iterable</strong> (<em>Iterable</em>) &#8211; The iterable to seperate.</li>
<li><strong>padvalue</strong> &#8211; A value to pad the last chunk with if <code class="code docutils literal"><span class="pre">n</span></code> does not
evenly divide len(list).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chunks</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s1">&#39;abcdefg&#39;</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
<span class="go">(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;)</span>
<span class="go">(&#39;d&#39;, &#39;e&#39;, &#39;f&#39;)</span>
<span class="go">(&#39;g&#39;, &#39;x&#39;, &#39;x&#39;)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.distributed.</code><code class="descname">distributed_tree_rBCM</code><span class="sig-paren">(</span><em>experts</em>, <em>weightfunction</em>, <em>clusterspec</em>, <em>worker_job='worker'</em>, <em>param_server_job='ps'</em>, <em>target_job=None</em>, <em>target_protocol='grpc'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#distributed_tree_rBCM"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Constructs a TreerBCM and distributes its computations.</p>
<dl class="docutils">
<dt>Preconditions:</dt>
<dd>if <code class="code docutils literal"><span class="pre">experts</span></code> is a sequence, the number of worker tasks must
evenly divide <code class="code docutils literal"><span class="pre">len(experts)</span></code>.</dd>
</dl>
<p>If <code class="code docutils literal"><span class="pre">experts</span></code> is a sequence, the architecture of the <code class="code docutils literal"><span class="pre">TreerBCM</span></code> will
be <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">m]</span></code>, where <code class="code docutils literal"><span class="pre">n</span></code> is the number of worker tasks and
<code class="code docutils literal"><span class="pre">m</span> <span class="pre">=</span> <span class="pre">len(experts)</span> <span class="pre">/</span> <span class="pre">n</span></code>. Each <code class="code docutils literal"><span class="pre">gPoEReduction</span></code> will be pinned to a
different worker task.</p>
<p>If <code class="code docutils literal"><span class="pre">experts</span></code> is a <code class="code docutils literal"><span class="pre">GPModel</span></code>, the architecture of the <code class="code docutils literal"><span class="pre">TreerBCM</span></code> will
be <code class="code docutils literal"><span class="pre">[n]</span></code>, where <code class="code docutils literal"><span class="pre">n</span></code> is the number of worker tasks. <code class="code docutils literal"><span class="pre">experts</span></code> will be
copied to fill out the architecture, with each copy being pinned to
a different worker task.</p>
<p><code class="code docutils literal"><span class="pre">Param</span></code>s will be pinned to parameter server tasks in a round-robin
fashion, based on the order they appear in <code class="code docutils literal"><span class="pre">TreerBCM.params</span></code>.</p>
<p>Additionally, the <code class="code docutils literal"><span class="pre">.tf_graph</span></code> of the <code class="code docutils literal"><span class="pre">TreerBCM</span></code> will be set to a
new graph and the <code class="code docutils literal"><span class="pre">.tf_session_target</span></code> will be set to either the
first task of the target job or the first task of the parameter
server job.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>experts</strong> (<em>GPModel | Sequence[GPModel]</em>) &#8211; The experts to
combine the opinions of. If this is a <code class="code docutils literal"><span class="pre">GPModel</span></code>, then it
will be shallow-copied to fill out the architecture.
If it is a sequence of <code class="code docutils literal"><span class="pre">GPModel</span></code>s, then the architecture
will have as many nodes in its final layer as
there are in the sequence.</li>
<li><strong>weightfunction</strong> (<em>Callable[[Sequence[GPModel], tf.Tensor, tf.Tensor, tf.Tensor], Tuple[tf.Tensor]]</em>) &#8211; A function used to calculate the weight of the experts.</li>
<li><strong>clusterspec</strong> (<em>tf.train.ClusterSpec</em>) &#8211; The cluster to
distribute tasks over.</li>
<li><strong>worker_job</strong> (<em>str</em>) &#8211; The job to assign computationally
expensive tasks to.</li>
<li><strong>param_server_job</strong> (<em>str</em>) &#8211; The job to assign paramaters to.</li>
<li><strong>target_job</strong> (<em>str | None</em>) &#8211; The job to coordinate other jobs
from. This is used to find the <code class="code docutils literal"><span class="pre">tf_session_target</span></code>.
If <code class="code docutils literal"><span class="pre">None</span></code>, the first task of <code class="code docutils literal"><span class="pre">param_server_job</span></code>
will be used as the session target. Otherwise, the
first task of the specified job is used.</li>
<li><strong>target_protocol</strong> (<em>str</em>) &#8211; The protocol to use when connecting to
the target server. Defaults to &#8216;grpc&#8217;.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.distributed.</code><code class="descname">equal_weights</code><span class="sig-paren">(</span><em>experts</em>, <em>X</em>, <em>Y</em>, <em>points</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#equal_weights"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Gives each expert an equal weight.</p>
<div class="math">
\[\forall k \in 0..M,\ β_k = 1 / M\]</div>
<p>where <span class="math">\(β_k\)</span> is the weight of the <span class="math">\(k\)</span>th expert at
every point and <span class="math">\(M\)</span> is the number of experts.</p>
<p>The dtype returned matches the dtype of <code class="code docutils literal"><span class="pre">points</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>experts</strong> (<em>Sequence[GPModel]</em>) &#8211; the experts to calculate
the weights of.</li>
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; the training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; the training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code>.</li>
<li><strong>points</strong> (<em>tf.Tensor</em>) &#8211; the points at which to calculate the
weights of the model, shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The weights of the experts at the
points. Each tensor has shape <code class="code docutils literal"><span class="pre">(num_points,</span> <span class="pre">num_latent)</span></code>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(Tuple[tf.Tensor])</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.distributed.</code><code class="descname">gPoEReduction</code><span class="sig-paren">(</span><em>children</em>, <em>weightfunction</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#gPoEReduction"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Combines the predictions of its children using the gPoE model.</p>
<p>The generalised Product of Experts (gPoE) model is similar to the
PoE model, except that we give each expert a weight. The variance
of the posterior distribution is a weighted harmonic mean of the
posterior variances of the child experts. The mean of the
posterior is a weighted sum of the means of the child experts
multiplied by the posterior variance.</p>
<div class="math">
\[\begin{split}σ^{-2}_{gPoE} &amp;= \sum_{k=1}^{M} β_k σ^{-2}_c \\
μ_{gPoE} &amp;= σ^2_{gPoE} \sum_{k=1}^{M} β_k μ_k σ^{-2}_k\end{split}\]</div>
<p>where <span class="math">\(μ_{gPoE}\)</span> and <span class="math">\(σ^2_{gPoE}\)</span> are the final posterior
mean and variance, <span class="math">\(M\)</span> is the number of child experts and
<span class="math">\(μ_k\)</span> and <span class="math">\(σ^2_k\)</span> are the posterior mean and variance
for the <span class="math">\(k\)</span>th child and <span class="math">\(β_k\)</span> is the weight of the
<span class="math">\(k\)</span>th child.</p>
<p>Note that when <span class="math">\(\sum_{k} β_k = 1\)</span>, the model falls back to
the prior outside the range of the data.</p>
<dl class="attribute">
<dt id="gptf.distributed.gPoEReduction.weightfunction">
<code class="descname">weightfunction</code><a class="headerlink" href="#gptf.distributed.gPoEReduction.weightfunction" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Callable[[Sequence[GPModel], tf.Tensor, tf.Tensor, tf.Tensor], Tuple[tf.Tensor]]</em> &#8211; A function used to calculate the weight of the experts.</p>
</dd></dl>

<p>For other attributes, see <code class="code docutils literal"><span class="pre">GPModel</span></code> and <code class="code docutils literal"><span class="pre">ParamList</span></code>.</p>
<dl class="method">
<dt>
<code class="descname">build_posterior_mean_var</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#gPoEReduction.build_posterior_mean_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds an op for the mean and variance of the posterior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.distributed.</code><code class="descname">ones_weights</code><span class="sig-paren">(</span><em>experts</em>, <em>X</em>, <em>Y</em>, <em>points</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#ones_weights"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>All weights are 1.</p>
<p>The dtype returned matches the dtype of <code class="code docutils literal"><span class="pre">points</span></code>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>experts</strong> (<em>Sequence[GPModel]</em>) &#8211; the experts to calculate
the weights of.</li>
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; the training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; the training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code>.</li>
<li><strong>points</strong> (<em>tf.Tensor</em>) &#8211; the points at which to calculate the
weights of the model, shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">The weights of the experts at the
points. Each tensor has shape <code class="code docutils literal"><span class="pre">(num_points,</span> <span class="pre">num_latent)</span></code>.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(Tuple[tf.Tensor])</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">gptf.distributed.</code><code class="descname">rBCMReduction</code><span class="sig-paren">(</span><em>children</em>, <em>weightfunction</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#rBCMReduction"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Combines the predictions of its children using the rBCM model.</p>
<p>In the Bayesian Committee Machine (rBCM) model, the variance of the
posterior distribution is the harmonic mean of the posterior
variances of the child experts, with a correction term based on
the prior variance and the sum of the weights. The mean of the
posterior is a weighted sum of the means of the child experts.</p>
<div class="math">
\[\begin{split}σ^{-2}_{rBCM} &amp;= (\sum_{k=1}^{M} β_k σ^{-2}_k)
              + (1 - \sum_{k=1}^{M} β_k) σ^{-2}_{\star\star}\\
μ_{rBCM} &amp;= σ^2_{rBCM} \sum_{k=1}^{M} β_k μ_k σ^{-2}_k\end{split}\]</div>
<p>where <span class="math">\(μ_{rBCM}\)</span> and <span class="math">\(σ^2_{rBCM}\)</span> are the final posterior
mean and variance, <span class="math">\(M\)</span> is the number of child experts,
<span class="math">\(σ^{-2}_{\star\star}\)</span> is the prior precision and
<span class="math">\(μ_k\)</span> and <span class="math">\(σ^2_k\)</span> are the posterior mean and variance
for the <span class="math">\(k\)</span>th child and <span class="math">\(β_k\)</span> is the weight of the
<span class="math">\(k\)</span>th child.</p>
<p>The model always falls back to the prior outside of the range of
the data.</p>
<dl class="attribute">
<dt id="gptf.distributed.rBCMReduction.weightfunction">
<code class="descname">weightfunction</code><a class="headerlink" href="#gptf.distributed.rBCMReduction.weightfunction" title="Permalink to this definition">¶</a></dt>
<dd><p><em>Callable[[Sequence[GPModel], tf.Tensor, tf.Tensor, tf.Tensor], Tuple[tf.Tensor]]</em> &#8211; A function used to calculate the weight of the experts.</p>
</dd></dl>

<p>For other attributes, see <code class="code docutils literal"><span class="pre">GPModel</span></code> and <code class="code docutils literal"><span class="pre">ParamList</span></code>.</p>
<dl class="method">
<dt>
<code class="descname">build_posterior_mean_var</code><span class="sig-paren">(</span><em>X</em>, <em>Y</em>, <em>test_points</em>, <em>full_cov=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#rBCMReduction.build_posterior_mean_var"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Builds an op for the mean and variance of the posterior(s).</p>
<p>In the returned tensors, the last index should always be the
latent function index.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>tf.Tensor</em>) &#8211; The training inputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">point_dims]</span></code></li>
<li><strong>Y</strong> (<em>tf.Tensor</em>) &#8211; The training outputs, shape <code class="code docutils literal"><span class="pre">[n,</span> <span class="pre">num_latent]</span></code></li>
<li><strong>test_points</strong> (<em>tf.Tensor</em>) &#8211; The points from the sample
space for which to predict means and variances
of the posterior distribution(s), shape
<code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">point_dims]</span></code>.</li>
<li><strong>full_cov</strong> (<em>bool</em>) &#8211; If <code class="code docutils literal"><span class="pre">False</span></code>, return an array of variances
at the test points. If <code class="code docutils literal"><span class="pre">True</span></code>, return the full
covariance matrix of the posterior distribution.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">A tensor that calculates the mean
at the test points with shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>, a tensor
that calculates either the variances at the test points
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">num_latent]</span></code>) or the full covariance matrix
(shape <code class="code docutils literal"><span class="pre">[m,</span> <span class="pre">m,</span> <span class="pre">num_latent]</span></code>).
Both tensors have the same dtype.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">(tf.Tensor, tf.Tensor)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt>
<code class="descclassname">gptf.distributed.</code><code class="descname">tree_rBCM</code><span class="sig-paren">(</span><em>experts</em>, <em>weightfunction</em>, <em>architecture</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/gptf/distributed.html#tree_rBCM"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>An rBCM, expressed as a tree of reductions.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>experts</strong> (<em>GPModel | Sequence[GPModel]</em>) &#8211; <p>The experts to
combine the opinions of. If this is a <code class="code docutils literal"><span class="pre">GPModel</span></code>, then it
will be shallow-copied to fill out the architecture.
If it is a sequence of <code class="code docutils literal"><span class="pre">GPModel</span></code>s, then the architecture
will have to have as many nodes in its final layer as
there are in the sequence, i.e.</p>
<blockquote>
<div>len(experts) == reduce(operator.mul,architecture,1)</div></blockquote>
</li>
<li><strong>weightfunction</strong> (<em>Callable[[Sequence[GPModel], tf.Tensor, tf.Tensor, tf.Tensor], Tuple[tf.Tensor]]</em>) &#8211; A function used to calculate the weight of the experts.</li>
<li><strong>architecture</strong> (<em>Sequence[int]</em>) &#8211; The branching factors at each
layer of the rBCM.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Public API</a><ul>
<li><a class="reference internal" href="#parameterized-classes">Parameterized classes</a></li>
<li><a class="reference internal" href="#autoflow">Autoflow</a></li>
<li><a class="reference internal" href="#models">Models</a></li>
<li><a class="reference internal" href="#public-core-modules">Public core modules</a><ul>
<li><a class="reference internal" href="#densities">densities</a></li>
<li><a class="reference internal" href="#transforms">transforms</a></li>
<li><a class="reference internal" href="#kernels">kernels</a></li>
<li><a class="reference internal" href="#likelihoods">likelihoods</a></li>
<li><a class="reference internal" href="#meanfunctions">meanfunctions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#gpr">GPR</a></li>
<li><a class="reference internal" href="#distributed">Distributed</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">Welcome to gptf&#8217;s documentation!</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/public_api.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Blaine Rogers.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.4.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
      |
      <a href="_sources/public_api.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>