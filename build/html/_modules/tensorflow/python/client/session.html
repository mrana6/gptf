<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml" lang="en-gb">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>tensorflow.python.client.session &#8212; gptf 1.1.0 documentation</title>
    
    <link rel="stylesheet" href="../../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../',
        VERSION:     '1.1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body role="document">
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for tensorflow.python.client.session</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>

<span class="sd">&quot;&quot;&quot;A client interface for TensorFlow.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>

<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">threading</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">tensorflow.core.protobuf</span> <span class="k">import</span> <span class="n">config_pb2</span>
<span class="kn">from</span> <span class="nn">tensorflow.python</span> <span class="k">import</span> <span class="n">pywrap_tensorflow</span> <span class="k">as</span> <span class="n">tf_session</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">errors</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.framework</span> <span class="k">import</span> <span class="n">sparse_tensor</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.ops</span> <span class="k">import</span> <span class="n">session_ops</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.platform</span> <span class="k">import</span> <span class="n">tf_logging</span> <span class="k">as</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">compat</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util</span> <span class="k">import</span> <span class="n">nest</span>


<span class="k">class</span> <span class="nc">SessionInterface</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Base class for implementations of TensorFlow client sessions.&quot;&quot;&quot;</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The underlying TensorFlow graph, to be used in building Operations.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;graph&#39;</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">sess_str</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The TensorFlow process to which this session will connect.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;sess_str&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs operations in the session. See `BaseSession.run()` for details.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;run&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">partial_run_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feeds</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets up the feeds and fetches for partial runs in the session.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;partial_run_setup&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">partial_run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Continues the execution with additional feeds and fetches.&quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;partial_run&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_get_indexed_slices_value_from_fetches</span><span class="p">(</span><span class="n">fetched_vals</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">IndexedSlicesValue</span><span class="p">(</span><span class="n">fetched_vals</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">fetched_vals</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">fetched_vals</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">fetched_vals</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_feeds_for_indexed_slices</span><span class="p">(</span><span class="n">feed</span><span class="p">,</span> <span class="n">feed_val</span><span class="p">):</span>
  <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">([</span><span class="n">feed</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="k">if</span> <span class="n">feed</span><span class="o">.</span><span class="n">dense_shape</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span>
                  <span class="p">[</span><span class="n">feed</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">],</span> <span class="n">feed_val</span><span class="p">))</span>


<span class="c1"># List of extensions supported to convert run arguments into actual fetches and</span>
<span class="c1"># feeds.</span>
<span class="c1">#</span>
<span class="c1"># Each element in the list is a tuple of (Type, fetch_fn, feed_fn1, feed_fn2),</span>
<span class="c1"># where the function signatures are:</span>
<span class="c1">#   fetch_fn : Type -&gt; (list of Tensors,</span>
<span class="c1">#                       lambda: list of fetched np.ndarray -&gt; TypeVal)</span>
<span class="c1">#   feed_fn1 : Type, TypeVal -&gt; list of (Tensor, value)</span>
<span class="c1">#   feed_fn2 : Type -&gt; list of Tensors</span>
<span class="c1">#</span>
<span class="c1"># `fetch_fn` describes how to expand fetch into its</span>
<span class="c1"># component Tensors and how to contract the fetched results back into</span>
<span class="c1"># a single return value.</span>
<span class="c1">#</span>
<span class="c1"># Each feed function describes how to unpack a single fed value and map it to</span>
<span class="c1"># feeds of one or more tensors and their corresponding values: `feed_fn1` is</span>
<span class="c1"># used to feed a run, `feed_fn2` to set up a partial run.</span>
<span class="c1">#</span>
<span class="c1"># TODO(touts): We could reimplement these as specialized _FeedMapper</span>
<span class="c1"># implementations after we refactor the feed handling code to use them.</span>
<span class="c1">#</span>
<span class="c1"># Eventually, this registration could be opened up to support custom Tensor</span>
<span class="c1"># expansions.</span>
<span class="c1"># pylint: disable=g-long-lambda</span>
<span class="n">_REGISTERED_EXPANSIONS</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># SparseTensors are fetched as SparseTensorValues. They can be fed</span>
    <span class="c1"># SparseTensorValues or normal tuples.</span>
    <span class="p">(</span><span class="n">sparse_tensor</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">,</span>
     <span class="k">lambda</span> <span class="n">fetch</span><span class="p">:</span> <span class="p">(</span>
         <span class="p">[</span><span class="n">fetch</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">fetch</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">fetch</span><span class="o">.</span><span class="n">shape</span><span class="p">],</span>
         <span class="k">lambda</span> <span class="n">fetched_vals</span><span class="p">:</span> <span class="n">sparse_tensor</span><span class="o">.</span><span class="n">SparseTensorValue</span><span class="p">(</span><span class="o">*</span><span class="n">fetched_vals</span><span class="p">)),</span>
     <span class="k">lambda</span> <span class="n">feed</span><span class="p">,</span> <span class="n">feed_val</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span>
         <span class="p">[</span><span class="n">feed</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">shape</span><span class="p">],</span> <span class="n">feed_val</span><span class="p">)),</span>
     <span class="k">lambda</span> <span class="n">feed</span><span class="p">:</span> <span class="p">[</span><span class="n">feed</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">shape</span><span class="p">]),</span>
    <span class="c1"># IndexedSlices are fetched as IndexedSlicesValues. They can be fed</span>
    <span class="c1"># IndexedSlicesValues or normal tuples.</span>
    <span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">IndexedSlices</span><span class="p">,</span>
     <span class="k">lambda</span> <span class="n">fetch</span><span class="p">:</span> <span class="p">(</span>
         <span class="p">[</span><span class="n">fetch</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">fetch</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="k">if</span> <span class="n">fetch</span><span class="o">.</span><span class="n">dense_shape</span> <span class="ow">is</span> <span class="kc">None</span>
         <span class="k">else</span> <span class="p">[</span><span class="n">fetch</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">fetch</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">fetch</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">],</span>
         <span class="n">_get_indexed_slices_value_from_fetches</span><span class="p">),</span>
     <span class="n">_get_feeds_for_indexed_slices</span><span class="p">,</span>
     <span class="k">lambda</span> <span class="n">feed</span><span class="p">:</span> <span class="p">[</span><span class="n">feed</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">indices</span><span class="p">]</span> <span class="k">if</span> <span class="n">feed</span><span class="o">.</span><span class="n">dense_shape</span> <span class="ow">is</span> <span class="kc">None</span>
     <span class="k">else</span> <span class="p">[</span><span class="n">feed</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">indices</span><span class="p">,</span> <span class="n">feed</span><span class="o">.</span><span class="n">dense_shape</span><span class="p">]),</span>
    <span class="c1"># The default catches all other types and performs no expansions.</span>
    <span class="p">(</span><span class="nb">object</span><span class="p">,</span>
     <span class="k">lambda</span> <span class="n">fetch</span><span class="p">:</span> <span class="p">([</span><span class="n">fetch</span><span class="p">],</span> <span class="k">lambda</span> <span class="n">fetched_vals</span><span class="p">:</span> <span class="n">fetched_vals</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
     <span class="k">lambda</span> <span class="n">feed</span><span class="p">,</span> <span class="n">feed_val</span><span class="p">:</span> <span class="p">[(</span><span class="n">feed</span><span class="p">,</span> <span class="n">feed_val</span><span class="p">)],</span>
     <span class="k">lambda</span> <span class="n">feed</span><span class="p">:</span> <span class="p">[</span><span class="n">feed</span><span class="p">])]</span>
<span class="c1"># pylint: enable=g-long-lambda</span>

<span class="k">def</span> <span class="nf">register_session_run_conversion_functions</span><span class="p">(</span><span class="n">tensor_type</span><span class="p">,</span> <span class="n">fetch_function</span><span class="p">,</span>
    <span class="n">feed_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">feed_function_for_partial_run</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Register fetch and feed conversion functions for `tf.Session.run()`.</span>

<span class="sd">  This function registers a triple of conversion functions for fetching and/or</span>
<span class="sd">  feeding values of user-defined types in a call to tf.Session.run().</span>

<span class="sd">  An example</span>

<span class="sd">  ```python</span>
<span class="sd">     class SquaredTensor(object):</span>
<span class="sd">       def __init__(self, tensor):</span>
<span class="sd">         self.sq = tf.square(tensor)</span>
<span class="sd">     #you can define conversion functions as follows:</span>
<span class="sd">     fetch_function = lambda squared_tensor:([squared_tensor.sq],</span>
<span class="sd">                                             lambda val: val[0])</span>
<span class="sd">     feed_function = lambda feed, feed_val: [(feed.sq, feed_val)]</span>
<span class="sd">     feed_function_for_partial_run = lambda feed: [feed.sq]</span>
<span class="sd">     #then after invoking this register function, you can use as follows:</span>
<span class="sd">     session.run(squared_tensor1,</span>
<span class="sd">                 feed_dict = {squared_tensor2 : some_numpy_array})</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">    tensor_type: The type for which you want to register a conversion function.</span>
<span class="sd">    fetch_function: A callable that takes an object of type `tensor_type` and</span>
<span class="sd">      returns a tuple, where the first element is a list of `tf.Tensor` objects,</span>
<span class="sd">      and the second element is a callable that takes a list of ndarrays and</span>
<span class="sd">      returns an object of some value type that corresponds to `tensor_type`.</span>
<span class="sd">      fetch_function describes how to expand fetch into its component Tensors</span>
<span class="sd">      and how to contract the fetched results back into a single return value.</span>
<span class="sd">    feed_function: A callable that takes feed_key and feed_value as input, and</span>
<span class="sd">      returns a list of tuples (feed_tensor, feed_val), feed_key must have type</span>
<span class="sd">      `tensor_type`, and feed_tensor must have type `tf.Tensor`. Each feed</span>
<span class="sd">      function describes how to unpack a single fed value and map it to feeds</span>
<span class="sd">      of one or more tensors and their corresponding values.</span>
<span class="sd">    feed_function_for_partial_run: A callable for specifying tensor values to</span>
<span class="sd">      feed when setting up a partial run, which takes a `tensor_type` type</span>
<span class="sd">      object as input, and returns a list of Tensors.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">for</span> <span class="n">conversion_function</span> <span class="ow">in</span> <span class="n">_REGISTERED_EXPANSIONS</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">conversion_function</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tensor_type</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> has already been registered so ignore it.&#39;</span><span class="p">,</span> <span class="n">tensor_type</span><span class="p">)</span>
      <span class="k">return</span>
  <span class="n">_REGISTERED_EXPANSIONS</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">(</span><span class="n">tensor_type</span><span class="p">,</span> <span class="n">fetch_function</span><span class="p">,</span> <span class="n">feed_function</span><span class="p">,</span> <span class="n">feed_function_for_partial_run</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">_FetchMapper</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Definition of the interface provided by fetch mappers.</span>

<span class="sd">  Fetch mappers are utility classes used by the _FetchHandler to handle</span>
<span class="sd">  arbitrary structures for the `fetch` argument to `Session.run()`.</span>

<span class="sd">  The `fetch` argument can be of various shapes: single tensor or op, list of</span>
<span class="sd">  fetches, tuple of fetches, namedtuple of fetches, or dict of fetches.  The</span>
<span class="sd">  structures can be arbitrarily nested.</span>

<span class="sd">  The low level run() API only wants a list of tensor or op names.  The various</span>
<span class="sd">  `_FetchMapper` subclasses below take care of handling the different shapes:</span>
<span class="sd">  uniquifying the fetches, and constructing results with the original shape.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">unique_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return the list of unique tensors or ops needed by this fetch mapper.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of tensors or ops.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Must be implemented by subclasses&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">build_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Build results that match the original shape of the fetch.</span>

<span class="sd">    Args:</span>
<span class="sd">      values: List of values returned by run(). The values correspond</span>
<span class="sd">        exactly to the list tensors or ops returned by unique_fetches().</span>

<span class="sd">    Returns:</span>
<span class="sd">      A struct of the same shape as the original fetch object handled by</span>
<span class="sd">      this fetch mapper.  In the returned struct, the original fetches are</span>
<span class="sd">      replaced by their fetched values.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Must be implemented by subclasses&#39;</span><span class="p">)</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">for_fetch</span><span class="p">(</span><span class="n">fetch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates fetch mapper that handles the structure of `fetch`.</span>

<span class="sd">    The default graph must be the one from which we want to fetch values when</span>
<span class="sd">    this function is called.</span>

<span class="sd">    Args:</span>
<span class="sd">      fetch: An arbitrary fetch structure: singleton, list, tuple,</span>
<span class="sd">        namedtuple, or dict.</span>

<span class="sd">    Returns:</span>
<span class="sd">      An instance of a subclass of `_FetchMapper` that handles the shape.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">fetch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Fetch argument </span><span class="si">%r</span><span class="s1"> has invalid type </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span>
                      <span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">fetch</span><span class="p">)))</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
      <span class="c1"># NOTE(touts): This is also the code path for namedtuples.</span>
      <span class="k">return</span> <span class="n">_ListFetchMapper</span><span class="p">(</span><span class="n">fetch</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">_DictFetchMapper</span><span class="p">(</span><span class="n">fetch</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># Look for a handler in the registered expansions.</span>
      <span class="k">for</span> <span class="n">tensor_type</span><span class="p">,</span> <span class="n">fetch_fn</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">_REGISTERED_EXPANSIONS</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="n">tensor_type</span><span class="p">):</span>
          <span class="n">fetches</span><span class="p">,</span> <span class="n">contraction_fn</span> <span class="o">=</span> <span class="n">fetch_fn</span><span class="p">(</span><span class="n">fetch</span><span class="p">)</span>
          <span class="k">return</span> <span class="n">_ElementFetchMapper</span><span class="p">(</span><span class="n">fetches</span><span class="p">,</span> <span class="n">contraction_fn</span><span class="p">)</span>
    <span class="c1"># Did not find anything.</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Fetch argument </span><span class="si">%r</span><span class="s1"> has invalid type </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span>
                    <span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">fetch</span><span class="p">)))</span>


<span class="k">class</span> <span class="nc">_ElementFetchMapper</span><span class="p">(</span><span class="n">_FetchMapper</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Fetch mapper for singleton tensors and ops.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">contraction_fn</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates an _ElementFetchMapper.</span>

<span class="sd">    This is the fetch mapper used for leaves in the fetch struct.  Because of</span>
<span class="sd">    the expansions mechanism, a leaf can actually fetch more than one tensor.</span>

<span class="sd">    Also note that the fetches here can be just strings (tensor or op names) or</span>
<span class="sd">    any other object that the graph knows how to convert to a tensor, such as a</span>
<span class="sd">    Variable.  So we have to run each fetch through `as_graph_element()` to get</span>
<span class="sd">    the corresponding tensor or op.</span>

<span class="sd">    Args:</span>
<span class="sd">      fetches: List of objects, as returned by a fetch_fn defined</span>
<span class="sd">        in _REGISTERED_EXPANSIONS.</span>
<span class="sd">      contraction_fn: Callable as returned by a fetch_fn.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_unique_fetches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fetch</span> <span class="ow">in</span> <span class="n">fetches</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_unique_fetches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_graph_element</span><span class="p">(</span>
            <span class="n">fetch</span><span class="p">,</span> <span class="n">allow_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">allow_operation</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
      <span class="k">except</span> <span class="ne">TypeError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Fetch argument </span><span class="si">%r</span><span class="s1"> has invalid type </span><span class="si">%r</span><span class="s1">, &#39;</span>
                        <span class="s1">&#39;must be a string or Tensor. (</span><span class="si">%s</span><span class="s1">)&#39;</span>
                        <span class="o">%</span> <span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">fetch</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)))</span>
      <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Fetch argument </span><span class="si">%r</span><span class="s1"> cannot be interpreted as a &#39;</span>
                         <span class="s1">&#39;Tensor. (</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)))</span>
      <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Fetch argument </span><span class="si">%r</span><span class="s1"> cannot be interpreted as a &#39;</span>
                         <span class="s1">&#39;Tensor. (</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">)))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_contraction_fn</span> <span class="o">=</span> <span class="n">contraction_fn</span>

  <span class="k">def</span> <span class="nf">unique_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unique_fetches</span>

  <span class="k">def</span> <span class="nf">build_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">values</span><span class="p">:</span>
      <span class="c1"># &#39;Operation&#39; case</span>
      <span class="k">return</span> <span class="kc">None</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_contraction_fn</span><span class="p">(</span><span class="n">values</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_uniquify_fetches</span><span class="p">(</span><span class="n">fetch_mappers</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Uniquifies fetches from a list of fetch_mappers.</span>

<span class="sd">  This is a utility function used by _ListFetchMapper and _DictFetchMapper.  It</span>
<span class="sd">  gathers all the unique fetches from a list of mappers and builds a list</span>
<span class="sd">  containing all of them but without duplicates (unique_fetches).</span>

<span class="sd">  It also returns a 2-D list of integers (values_indices) indicating at which</span>
<span class="sd">  index in unique_fetches the fetches of the mappers are located.</span>

<span class="sd">  This list is as follows:</span>
<span class="sd">    values_indices[mapper_index][mapper_fetch_index] = unique_fetches_index</span>

<span class="sd">  Args:</span>
<span class="sd">    fetch_mappers: list of fetch mappers.</span>

<span class="sd">  Returns:</span>
<span class="sd">    A list of fetches.</span>
<span class="sd">    A 2-D list of integers.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">unique_fetches</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">value_indices</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">seen_fetches</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">fetch_mappers</span><span class="p">:</span>
    <span class="n">m_value_indices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">unique_fetches</span><span class="p">():</span>
      <span class="n">j</span> <span class="o">=</span> <span class="n">seen_fetches</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">j</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">j</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">seen_fetches</span><span class="p">)</span>
        <span class="n">seen_fetches</span><span class="p">[</span><span class="n">f</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span>
        <span class="n">unique_fetches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
      <span class="n">m_value_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">j</span><span class="p">)</span>
    <span class="n">value_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m_value_indices</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">unique_fetches</span><span class="p">,</span> <span class="n">value_indices</span>


<span class="k">class</span> <span class="nc">_ListFetchMapper</span><span class="p">(</span><span class="n">_FetchMapper</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Fetch mapper for lists, tuples, and namedtuples.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetches</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a _ListFetchMapper.</span>

<span class="sd">    Args:</span>
<span class="sd">      fetches: List, tuple, or namedtuple of fetches.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">fetches</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_mappers</span> <span class="o">=</span> <span class="p">[</span><span class="n">_FetchMapper</span><span class="o">.</span><span class="n">for_fetch</span><span class="p">(</span><span class="n">fetch</span><span class="p">)</span> <span class="k">for</span> <span class="n">fetch</span> <span class="ow">in</span> <span class="n">fetches</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_unique_fetches</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_value_indices</span> <span class="o">=</span> <span class="n">_uniquify_fetches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mappers</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">unique_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unique_fetches</span>

  <span class="k">def</span> <span class="nf">build_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="c1"># Create the list of results for each mapper.</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">vi</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mappers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_value_indices</span><span class="p">):</span>
      <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">build_results</span><span class="p">([</span><span class="n">values</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">vi</span><span class="p">]))</span>
    <span class="c1"># Return a value of the original type of the fetches.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_type</span> <span class="o">==</span> <span class="nb">list</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">results</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_type</span> <span class="o">==</span> <span class="nb">tuple</span><span class="p">:</span>
      <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># This is the code path for namedtuple.</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_type</span><span class="p">(</span><span class="o">*</span><span class="n">results</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_DictFetchMapper</span><span class="p">(</span><span class="n">_FetchMapper</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Fetch mapper for dicts.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetches</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a _DictFetchMapper.</span>

<span class="sd">    Args:</span>
<span class="sd">      fetches: Dict of fetches.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_keys</span> <span class="o">=</span> <span class="n">fetches</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_mappers</span> <span class="o">=</span> <span class="p">[</span><span class="n">_FetchMapper</span><span class="o">.</span><span class="n">for_fetch</span><span class="p">(</span><span class="n">fetch</span><span class="p">)</span>
                     <span class="k">for</span> <span class="n">fetch</span> <span class="ow">in</span> <span class="n">fetches</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_unique_fetches</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_value_indices</span> <span class="o">=</span> <span class="n">_uniquify_fetches</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_mappers</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">unique_fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unique_fetches</span>

  <span class="k">def</span> <span class="nf">build_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">values</span><span class="p">):</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">vi</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_keys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mappers</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_value_indices</span><span class="p">):</span>
      <span class="n">results</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">build_results</span><span class="p">([</span><span class="n">values</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">vi</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">results</span>


<span class="k">class</span> <span class="nc">_FetchHandler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Handler for structured fetches.</span>

<span class="sd">  Given a graph, a user-provided structure for fetches, and a feed dict, this</span>
<span class="sd">  class takes care of generating a list of tensor names to fetch and op names</span>
<span class="sd">  to run for a low level `run()` call.</span>

<span class="sd">  Given the results of the low level run call, this class can also rebuild a</span>
<span class="sd">  result structure matching the user-provided structure for fetches, but</span>
<span class="sd">  containing the corresponding results.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># TODO(touts): Make this class also take care of destructuring the feed</span>
  <span class="c1"># dict instead of doing it in the callers.</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feeds</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a fetch handler.</span>

<span class="sd">    Args:</span>
<span class="sd">      graph: Graph of the fetches.   Used to check for fetchability</span>
<span class="sd">        and to convert all fetches to tensors or ops as needed.</span>
<span class="sd">      fetches: An arbitrary fetch structure: singleton, list, tuple,</span>
<span class="sd">        namedtuple, or dict.</span>
<span class="sd">      feeds: A feed dict where keys are fully resolved tensor names.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_mapper</span> <span class="o">=</span> <span class="n">_FetchMapper</span><span class="o">.</span><span class="n">for_fetch</span><span class="p">(</span><span class="n">fetches</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_fetches</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_targets</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_feeds</span> <span class="o">=</span> <span class="n">feeds</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_handles</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">fetch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_mapper</span><span class="o">.</span><span class="n">unique_fetches</span><span class="p">():</span>
      <span class="n">fetch_name</span> <span class="o">=</span> <span class="n">compat</span><span class="o">.</span><span class="n">as_bytes</span><span class="p">(</span><span class="n">fetch</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Operation</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_assert_fetchable</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">fetch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_targets</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fetch_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_assert_fetchable</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">fetch</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fetches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fetch_name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
      <span class="c1"># Remember the fetch if it is for a tensor handle.</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fetch</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">fetch</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s1">&#39;GetSessionHandle&#39;</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_handles</span><span class="p">[</span><span class="n">fetch_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">fetch</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_final_fetches</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fetches</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">feeds</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">_assert_fetchable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">op</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">graph</span><span class="o">.</span><span class="n">is_fetchable</span><span class="p">(</span><span class="n">op</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
          <span class="s1">&#39;Operation </span><span class="si">%r</span><span class="s1"> has been marked as not fetchable.&#39;</span> <span class="o">%</span> <span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">fetches</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return the unique names of tensors to fetch.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of strings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_fetches</span>

  <span class="k">def</span> <span class="nf">targets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return the unique names of ops to run.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of strings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_targets</span>

  <span class="k">def</span> <span class="nf">build_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">session</span><span class="p">,</span> <span class="n">tensor_values</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Build results matching the original fetch shape.</span>

<span class="sd">    `tensor_values` must be a list of the same length as</span>
<span class="sd">    the one returned by `fetches()`, and holding the requested</span>
<span class="sd">    fetch values.</span>

<span class="sd">    This method builds a struct with the same shape as the original `fetches`</span>
<span class="sd">    passed to the constructor, in which the fetches are replaced by their</span>
<span class="sd">    fetched value.</span>

<span class="sd">    Args:</span>
<span class="sd">      session: The enclosing session.  Used for tensor handles.</span>
<span class="sd">      tensor_values: List of values matching the list returned</span>
<span class="sd">        by fetches().</span>

<span class="sd">    Returns:</span>
<span class="sd">      A structure of the same shape as the original `fetches` argument but</span>
<span class="sd">        containing tensors or None (for fetched ops).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">full_values</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_final_fetches</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor_values</span><span class="p">)</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">is_op</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ops</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">is_op</span><span class="p">:</span>
        <span class="n">full_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="c1"># If the fetch was in the feeds, use the fed value, otherwise</span>
        <span class="c1"># use the returned value.</span>
        <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_feeds</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fetches</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
          <span class="n">value</span> <span class="o">=</span> <span class="n">tensor_values</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
          <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_handles</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fetches</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">dtype</span><span class="p">:</span>
          <span class="n">full_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">session_ops</span><span class="o">.</span><span class="n">TensorHandle</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">session</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">full_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">assert</span> <span class="n">j</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">tensor_values</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fetch_mapper</span><span class="o">.</span><span class="n">build_results</span><span class="p">(</span><span class="n">full_values</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">BaseSession</span><span class="p">(</span><span class="n">SessionInterface</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A class for interacting with a TensorFlow computation.</span>

<span class="sd">  The BaseSession enables incremental graph building with inline</span>
<span class="sd">  execution of Operations and evaluation of Tensors.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Constructs a new TensorFlow session.</span>

<span class="sd">    Args:</span>
<span class="sd">      target: (Optional) The TensorFlow execution engine to connect to.</span>
<span class="sd">      graph: (Optional) The graph to be used. If this argument is None,</span>
<span class="sd">        the default graph will be used.</span>
<span class="sd">      config: (Optional) ConfigProto proto used to configure the session.</span>

<span class="sd">    Raises:</span>
<span class="sd">      tf.errors.OpError: Or one of its subclasses if an error occurs while</span>
<span class="sd">        creating the TensorFlow session.</span>
<span class="sd">      TypeError: If one of the arguments has the wrong type.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">graph</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Graph</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;graph must be a tf.Graph, but got </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">graph</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span> <span class="o">=</span> <span class="n">graph</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_opened</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_current_version</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_extend_lock</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_target</span> <span class="o">=</span> <span class="n">compat</span><span class="o">.</span><span class="n">as_bytes</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
      <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;target must be a string, but got </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_target</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_delete_lock</span> <span class="o">=</span> <span class="n">threading</span><span class="o">.</span><span class="n">Lock</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_dead_handles</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">if</span> <span class="n">config</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">config_pb2</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;config must be a tf.ConfigProto, but got </span><span class="si">%s</span><span class="s1">&#39;</span>
                        <span class="o">%</span> <span class="nb">type</span><span class="p">(</span><span class="n">config</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="n">config</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_add_shapes</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">graph_options</span><span class="o">.</span><span class="n">infer_shapes</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_config</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_add_shapes</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_session</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">opts</span> <span class="o">=</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_NewSessionOptions</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_target</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="k">with</span> <span class="n">errors</span><span class="o">.</span><span class="n">raise_exception_on_not_ok_status</span><span class="p">()</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_session</span> <span class="o">=</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_NewDeprecatedSession</span><span class="p">(</span><span class="n">opts</span><span class="p">,</span> <span class="n">status</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
      <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_DeleteSessionOptions</span><span class="p">(</span><span class="n">opts</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Closes this session.</span>

<span class="sd">    Calling this method frees all resources associated with the session.</span>

<span class="sd">    Raises:</span>
<span class="sd">      tf.errors.OpError: Or one of its subclasses if an error occurs while</span>
<span class="sd">        closing the TensorFlow session.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extend_lock</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_opened</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">with</span> <span class="n">errors</span><span class="o">.</span><span class="n">raise_exception_on_not_ok_status</span><span class="p">()</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
          <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_CloseDeprecatedSession</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_session</span><span class="p">,</span> <span class="n">status</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">__del__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># cleanly ignore all exceptions</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>  <span class="c1"># pylint: disable=broad-except</span>
      <span class="k">pass</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_session</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="n">status</span> <span class="o">=</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_NewStatus</span><span class="p">()</span>
        <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_DeleteDeprecatedSession</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_session</span><span class="p">,</span> <span class="n">status</span><span class="p">)</span>
      <span class="k">finally</span><span class="p">:</span>
        <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_DeleteStatus</span><span class="p">(</span><span class="n">status</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_session</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;The graph that was launched in this session.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">graph_def</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A serializable version of the underlying TensorFlow graph.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A graph_pb2.GraphDef proto containing nodes for all of the Operations in</span>
<span class="sd">      the underlying TensorFlow graph.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">(</span><span class="n">add_shapes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_add_shapes</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">sess_str</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_target</span>

  <span class="k">def</span> <span class="nf">as_default</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a context manager that makes this object the default session.</span>

<span class="sd">    Use with the `with` keyword to specify that calls to</span>
<span class="sd">    [`Operation.run()`](../../api_docs/python/framework.md#Operation.run) or</span>
<span class="sd">    [`Tensor.eval()`](../../api_docs/python/framework.md#Tensor.eval) should be</span>
<span class="sd">    executed in this session.</span>

<span class="sd">    ```python</span>
<span class="sd">    c = tf.constant(..)</span>
<span class="sd">    sess = tf.Session()</span>

<span class="sd">    with sess.as_default():</span>
<span class="sd">      assert tf.get_default_session() is sess</span>
<span class="sd">      print(c.eval())</span>
<span class="sd">    ```</span>

<span class="sd">    To get the current default session, use</span>
<span class="sd">    [`tf.get_default_session()`](#get_default_session).</span>


<span class="sd">    *N.B.* The `as_default` context manager *does not* close the</span>
<span class="sd">    session when you exit the context, and you must close the session</span>
<span class="sd">    explicitly.</span>

<span class="sd">    ```python</span>
<span class="sd">    c = tf.constant(...)</span>
<span class="sd">    sess = tf.Session()</span>
<span class="sd">    with sess.as_default():</span>
<span class="sd">      print(c.eval())</span>
<span class="sd">    # ...</span>
<span class="sd">    with sess.as_default():</span>
<span class="sd">      print(c.eval())</span>

<span class="sd">    sess.close()</span>
<span class="sd">    ```</span>

<span class="sd">    Alternatively, you can use `with tf.Session():` to create a</span>
<span class="sd">    session that is automatically closed on exiting the context,</span>
<span class="sd">    including when an uncaught exception is raised.</span>

<span class="sd">    *N.B.* The default graph is a property of the current thread. If you</span>
<span class="sd">    create a new thread, and wish to use the default session in that</span>
<span class="sd">    thread, you must explicitly add a `with sess.as_default():` in that</span>
<span class="sd">    thread&#39;s function.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A context manager using this session as the default session.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">ops</span><span class="o">.</span><span class="n">default_session</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">run_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs operations and evaluates tensors in `fetches`.</span>

<span class="sd">    This method runs one &quot;step&quot; of TensorFlow computation, by</span>
<span class="sd">    running the necessary graph fragment to execute every `Operation`</span>
<span class="sd">    and evaluate every `Tensor` in `fetches`, substituting the values in</span>
<span class="sd">    `feed_dict` for the corresponding input values.</span>

<span class="sd">    The `fetches` argument may be a single graph element, or an arbitrarily</span>
<span class="sd">    nested list, tuple, namedtuple, or dict containing graph elements at its</span>
<span class="sd">    leaves.  A graph element can be one of the following types:</span>

<span class="sd">    * An [`Operation`](../../api_docs/python/framework.md#Operation).</span>
<span class="sd">      The corresponding fetched value will be `None`.</span>
<span class="sd">    * A [`Tensor`](../../api_docs/python/framework.md#Tensor).</span>
<span class="sd">      The corresponding fetched value will be a numpy ndarray containing the</span>
<span class="sd">      value of that tensor.</span>
<span class="sd">    * A [`SparseTensor`](../../api_docs/python/sparse_ops.md#SparseTensor).</span>
<span class="sd">      The corresponding fetched value will be a</span>
<span class="sd">      [`SparseTensorValue`](../../api_docs/python/sparse_ops.md#SparseTensorValue)</span>
<span class="sd">      containing the value of that sparse tensor.</span>
<span class="sd">    * A `get_tensor_handle` op.  The corresponding fetched value will be a</span>
<span class="sd">      numpy ndarray containing the handle of that tensor.</span>
<span class="sd">    * A `string` which is the name of a tensor or operation in the graph.</span>

<span class="sd">    The value returned by `run()` has the same shape as the `fetches` argument,</span>
<span class="sd">    where the leaves are replaced by the corresponding values returned by</span>
<span class="sd">    TensorFlow.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">       a = tf.constant([10, 20])</span>
<span class="sd">       b = tf.constant([1.0, 2.0])</span>
<span class="sd">       # &#39;fetches&#39; can be a singleton</span>
<span class="sd">       v = session.run(a)</span>
<span class="sd">       # v is the numpy array [10, 20]</span>
<span class="sd">       # &#39;fetches&#39; can be a list.</span>
<span class="sd">       v = session.run([a, b])</span>
<span class="sd">       # v a Python list with 2 numpy arrays: the numpy array [10, 20] and the</span>
<span class="sd">       # 1-D array [1.0, 2.0]</span>
<span class="sd">       # &#39;fetches&#39; can be arbitrary lists, tuples, namedtuple, dicts:</span>
<span class="sd">       MyData = collections.namedtuple(&#39;MyData&#39;, [&#39;a&#39;, &#39;b&#39;])</span>
<span class="sd">       v = session.run({&#39;k1&#39;: MyData(a, b), &#39;k2&#39;: [b, a]})</span>
<span class="sd">       # v is a dict with</span>
<span class="sd">       # v[&#39;k1&#39;] is a MyData namedtuple with &#39;a&#39; the numpy array [10, 20] and</span>
<span class="sd">       # &#39;b&#39; the numpy array [1.0, 2.0]</span>
<span class="sd">       # v[&#39;k2&#39;] is a list with the numpy array [1.0, 2.0] and the numpy array</span>
<span class="sd">       # [10, 20].</span>
<span class="sd">    ```</span>

<span class="sd">    The optional `feed_dict` argument allows the caller to override</span>
<span class="sd">    the value of tensors in the graph. Each key in `feed_dict` can be</span>
<span class="sd">    one of the following types:</span>

<span class="sd">    * If the key is a [`Tensor`](../../api_docs/python/framework.md#Tensor), the</span>
<span class="sd">      value may be a Python scalar, string, list, or numpy ndarray</span>
<span class="sd">      that can be converted to the same `dtype` as that</span>
<span class="sd">      tensor. Additionally, if the key is a</span>
<span class="sd">      [placeholder](../../api_docs/python/io_ops.md#placeholder), the shape of</span>
<span class="sd">      the value will be checked for compatibility with the placeholder.</span>
<span class="sd">    * If the key is a</span>
<span class="sd">      [`SparseTensor`](../../api_docs/python/sparse_ops.md#SparseTensor),</span>
<span class="sd">      the value should be a</span>
<span class="sd">      [`SparseTensorValue`](../../api_docs/python/sparse_ops.md#SparseTensorValue).</span>
<span class="sd">    * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value</span>
<span class="sd">      should be a nested tuple with the same structure that maps to their</span>
<span class="sd">      corresponding values as above.</span>

<span class="sd">    Each value in `feed_dict` must be convertible to a numpy array of the dtype</span>
<span class="sd">    of the corresponding key.</span>

<span class="sd">    The optional `options` argument expects a [`RunOptions`] proto. The options</span>
<span class="sd">    allow controlling the behavior of this particular step (e.g. turning tracing</span>
<span class="sd">    on).</span>

<span class="sd">    The optional `run_metadata` argument expects a [`RunMetadata`] proto. When</span>
<span class="sd">    appropriate, the non-Tensor output of this step will be collected there. For</span>
<span class="sd">    example, when users turn on tracing in `options`, the profiled info will be</span>
<span class="sd">    collected into this argument and passed back.</span>

<span class="sd">    Args:</span>
<span class="sd">      fetches: A single graph element, a list of graph elements,</span>
<span class="sd">        or a dictionary whose values are graph elements or lists of graph</span>
<span class="sd">        elements (described above).</span>
<span class="sd">      feed_dict: A dictionary that maps graph elements to values</span>
<span class="sd">        (described above).</span>
<span class="sd">      options: A [`RunOptions`] protocol buffer</span>
<span class="sd">      run_metadata: A [`RunMetadata`] protocol buffer</span>

<span class="sd">    Returns:</span>
<span class="sd">      Either a single value if `fetches` is a single graph element, or</span>
<span class="sd">      a list of values if `fetches` is a list, or a dictionary with the</span>
<span class="sd">      same keys as `fetches` if that is a dictionary (described above).</span>

<span class="sd">    Raises:</span>
<span class="sd">      RuntimeError: If this `Session` is in an invalid state (e.g. has been</span>
<span class="sd">        closed).</span>
<span class="sd">      TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.</span>
<span class="sd">      ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a</span>
<span class="sd">        `Tensor` that doesn&#39;t exist.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">run_metadata_ptr</span> <span class="o">=</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_NewBuffer</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">options</span><span class="p">:</span>
      <span class="n">options_ptr</span> <span class="o">=</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_NewBufferFromString</span><span class="p">(</span>
          <span class="n">compat</span><span class="o">.</span><span class="n">as_bytes</span><span class="p">(</span><span class="n">options</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">options_ptr</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">try</span><span class="p">:</span>
      <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span> <span class="n">options_ptr</span><span class="p">,</span>
                         <span class="n">run_metadata_ptr</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">run_metadata</span><span class="p">:</span>
        <span class="n">proto_data</span> <span class="o">=</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_GetBuffer</span><span class="p">(</span><span class="n">run_metadata_ptr</span><span class="p">)</span>
        <span class="n">run_metadata</span><span class="o">.</span><span class="n">ParseFromString</span><span class="p">(</span><span class="n">compat</span><span class="o">.</span><span class="n">as_bytes</span><span class="p">(</span><span class="n">proto_data</span><span class="p">))</span>
    <span class="k">finally</span><span class="p">:</span>
      <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_DeleteBuffer</span><span class="p">(</span><span class="n">run_metadata_ptr</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">options</span><span class="p">:</span>
        <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_DeleteBuffer</span><span class="p">(</span><span class="n">options_ptr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>

  <span class="k">def</span> <span class="nf">partial_run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Continues the execution with more feeds and fetches.</span>

<span class="sd">    This is EXPERIMENTAL and subject to change.</span>

<span class="sd">    To use partial execution, a user first calls `partial_run_setup()` and</span>
<span class="sd">    then a sequence of `partial_run()`. `partial_run_setup` specifies the</span>
<span class="sd">    list of feeds and fetches that will be used in the subsequent</span>
<span class="sd">    `partial_run` calls.</span>

<span class="sd">    The optional `feed_dict` argument allows the caller to override</span>
<span class="sd">    the value of tensors in the graph. See run() for more information.</span>

<span class="sd">    Below is a simple example:</span>

<span class="sd">    ```python</span>
<span class="sd">    a = array_ops.placeholder(dtypes.float32, shape=[])</span>
<span class="sd">    b = array_ops.placeholder(dtypes.float32, shape=[])</span>
<span class="sd">    c = array_ops.placeholder(dtypes.float32, shape=[])</span>
<span class="sd">    r1 = math_ops.add(a, b)</span>
<span class="sd">    r2 = math_ops.mul(r1, c)</span>

<span class="sd">    h = sess.partial_run_setup([r1, r2], [a, b, c])</span>
<span class="sd">    res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})</span>
<span class="sd">    res = sess.partial_run(h, r2, feed_dict={c: res})</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      handle: A handle for a sequence of partial runs.</span>
<span class="sd">      fetches: A single graph element, a list of graph elements,</span>
<span class="sd">        or a dictionary whose values are graph elements or lists of graph</span>
<span class="sd">        elements (see documentation for `run`).</span>
<span class="sd">      feed_dict: A dictionary that maps graph elements to values</span>
<span class="sd">        (described above).</span>

<span class="sd">    Returns:</span>
<span class="sd">      Either a single value if `fetches` is a single graph element, or</span>
<span class="sd">      a list of values if `fetches` is a list, or a dictionary with the</span>
<span class="sd">      same keys as `fetches` if that is a dictionary</span>
<span class="sd">      (see documentation for `run`).</span>

<span class="sd">    Raises:</span>
<span class="sd">      tf.errors.OpError: Or one of its subclasses on error.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># TODO(touts): Support feeding and fetching the same tensor.</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_run</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">partial_run_setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feeds</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets up a graph with feeds and fetches for partial run.</span>

<span class="sd">    This is EXPERIMENTAL and subject to change.</span>

<span class="sd">    Note that contrary to `run`, `feeds` only specifies the graph elements.</span>
<span class="sd">    The tensors will be supplied by the subsequent `partial_run` calls.</span>

<span class="sd">    Args:</span>
<span class="sd">      fetches: A single graph element, or a list of graph elements.</span>
<span class="sd">      feeds: A single graph element, or a list of graph elements.</span>

<span class="sd">    Returns:</span>
<span class="sd">      A handle for partial run.</span>

<span class="sd">    Raises:</span>
<span class="sd">      RuntimeError: If this `Session` is in an invalid state (e.g. has been</span>
<span class="sd">        closed).</span>
<span class="sd">      TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.</span>
<span class="sd">      tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">_feed_fn</span><span class="p">(</span><span class="n">feed</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">tensor_type</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">feed_fn</span> <span class="ow">in</span> <span class="n">_REGISTERED_EXPANSIONS</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feed</span><span class="p">,</span> <span class="n">tensor_type</span><span class="p">):</span>
          <span class="k">return</span> <span class="n">feed_fn</span><span class="p">(</span><span class="n">feed</span><span class="p">)</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Feed argument </span><span class="si">%r</span><span class="s1"> has invalid type </span><span class="si">%r</span><span class="s1">&#39;</span>
                      <span class="o">%</span> <span class="p">(</span><span class="n">feed</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">feed</span><span class="p">)))</span>

    <span class="c1"># Check session.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Attempted to use a closed Session.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">version</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;The Session graph is empty.  Add operations to the &#39;</span>
                         <span class="s1">&#39;graph before calling run().&#39;</span><span class="p">)</span>

    <span class="c1"># Create request.</span>
    <span class="n">feed_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Validate and process feed_list.</span>
    <span class="n">is_list_feed</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feeds</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">is_list_feed</span><span class="p">:</span>
      <span class="n">feeds</span> <span class="o">=</span> <span class="p">[</span><span class="n">feeds</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">feed</span> <span class="ow">in</span> <span class="n">feeds</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">subfeed</span> <span class="ow">in</span> <span class="n">_feed_fn</span><span class="p">(</span><span class="n">feed</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
          <span class="n">subfeed_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_graph_element</span><span class="p">(</span><span class="n">subfeed</span><span class="p">,</span> <span class="n">allow_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                  <span class="n">allow_operation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="n">feed_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">compat</span><span class="o">.</span><span class="n">as_bytes</span><span class="p">(</span><span class="n">subfeed_t</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
          <span class="n">e</span><span class="o">.</span><span class="n">message</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;Cannot interpret feed_list key as Tensor: &#39;</span>
                       <span class="o">+</span> <span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>
          <span class="n">e</span><span class="o">.</span><span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">,)</span>
          <span class="k">raise</span> <span class="n">e</span>

    <span class="c1"># Validate and process fetches.</span>
    <span class="c1"># TODO(touts): Support feeding and fetching the same tensor.</span>
    <span class="n">fetch_handler</span> <span class="o">=</span> <span class="n">_FetchHandler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="p">{})</span>

    <span class="c1"># Set up a graph with feeds and fetches for partial run.</span>
    <span class="k">def</span> <span class="nf">_setup_fn</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">feed_list</span><span class="p">,</span> <span class="n">fetch_list</span><span class="p">,</span> <span class="n">target_list</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_extend_graph</span><span class="p">()</span>
      <span class="k">with</span> <span class="n">errors</span><span class="o">.</span><span class="n">raise_exception_on_not_ok_status</span><span class="p">()</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_PRunSetup</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">feed_list</span><span class="p">,</span> <span class="n">fetch_list</span><span class="p">,</span>
                                       <span class="n">target_list</span><span class="p">,</span> <span class="n">status</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_call</span><span class="p">(</span><span class="n">_setup_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_session</span><span class="p">,</span> <span class="n">feed_list</span><span class="p">,</span>
                         <span class="n">fetch_handler</span><span class="o">.</span><span class="n">fetches</span><span class="p">(),</span> <span class="n">fetch_handler</span><span class="o">.</span><span class="n">targets</span><span class="p">())</span>

  <span class="k">def</span> <span class="nf">_run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform either run or partial_run, depending the presence of `handle`.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">_feed_fn</span><span class="p">(</span><span class="n">feed</span><span class="p">,</span> <span class="n">feed_val</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">tensor_type</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">feed_fn</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">_REGISTERED_EXPANSIONS</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">feed</span><span class="p">,</span> <span class="n">tensor_type</span><span class="p">):</span>
          <span class="k">return</span> <span class="n">feed_fn</span><span class="p">(</span><span class="n">feed</span><span class="p">,</span> <span class="n">feed_val</span><span class="p">)</span>
      <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Feed argument </span><span class="si">%r</span><span class="s1"> has invalid type </span><span class="si">%r</span><span class="s1">&#39;</span>
                      <span class="o">%</span> <span class="p">(</span><span class="n">feed</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">feed</span><span class="p">)))</span>

    <span class="c1"># Check session.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_closed</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Attempted to use a closed Session.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">version</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;The Session graph is empty.  Add operations to the &#39;</span>
                         <span class="s1">&#39;graph before calling run().&#39;</span><span class="p">)</span>

    <span class="c1"># Create request.</span>
    <span class="n">feed_dict_string</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">feed_map</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Validate and process feed_dict.</span>
    <span class="k">if</span> <span class="n">feed_dict</span><span class="p">:</span>
      <span class="n">feed_dict</span> <span class="o">=</span> <span class="n">nest</span><span class="o">.</span><span class="n">flatten_dict_items</span><span class="p">(</span><span class="n">feed_dict</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">feed</span><span class="p">,</span> <span class="n">feed_val</span> <span class="ow">in</span> <span class="n">feed_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">subfeed</span><span class="p">,</span> <span class="n">subfeed_val</span> <span class="ow">in</span> <span class="n">_feed_fn</span><span class="p">(</span><span class="n">feed</span><span class="p">,</span> <span class="n">feed_val</span><span class="p">):</span>
          <span class="k">try</span><span class="p">:</span>
            <span class="n">subfeed_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_graph_element</span><span class="p">(</span><span class="n">subfeed</span><span class="p">,</span> <span class="n">allow_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                    <span class="n">allow_operation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
          <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Cannot interpret feed_dict key as Tensor: &#39;</span>
                            <span class="o">+</span> <span class="n">e</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

          <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">subfeed_val</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;The value of a feed cannot be a tf.Tensor object. &#39;</span>
                            <span class="s1">&#39;Acceptable feed values include Python scalars, &#39;</span>
                            <span class="s1">&#39;strings, lists, or numpy ndarrays.&#39;</span><span class="p">)</span>

          <span class="n">subfeed_dtype</span> <span class="o">=</span> <span class="n">subfeed_t</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">as_numpy_dtype</span>
          <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">subfeed_val</span><span class="p">,</span>
                        <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">subfeed_dtype</span><span class="p">(</span><span class="n">subfeed_val</span><span class="p">)</span> <span class="o">!=</span> <span class="n">subfeed_val</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;Type of feed value &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">subfeed_val</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; is not&#39;</span>
                <span class="s1">&#39; compatible with Tensor type &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">subfeed_dtype</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span>
                <span class="s1">&#39; Try explicitly setting the type of the feed tensor&#39;</span>
                <span class="s1">&#39; to a larger type (e.g. int64).&#39;</span><span class="p">)</span>

          <span class="n">np_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">subfeed_val</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">subfeed_dtype</span><span class="p">)</span>

          <span class="k">if</span> <span class="ow">not</span> <span class="n">subfeed_t</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">np_val</span><span class="o">.</span><span class="n">shape</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Cannot feed value of shape </span><span class="si">%r</span><span class="s1"> for Tensor </span><span class="si">%r</span><span class="s1">, &#39;</span>
                <span class="s1">&#39;which has shape </span><span class="si">%r</span><span class="s1">&#39;</span>
                <span class="o">%</span> <span class="p">(</span><span class="n">np_val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">subfeed_t</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">subfeed_t</span><span class="o">.</span><span class="n">get_shape</span><span class="p">())))</span>
          <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">is_feedable</span><span class="p">(</span><span class="n">subfeed_t</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Tensor </span><span class="si">%s</span><span class="s1"> may not be fed.&#39;</span> <span class="o">%</span> <span class="n">subfeed_t</span><span class="p">)</span>
          <span class="n">subfeed_name</span> <span class="o">=</span> <span class="n">compat</span><span class="o">.</span><span class="n">as_bytes</span><span class="p">(</span><span class="n">subfeed_t</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
          <span class="n">feed_dict_string</span><span class="p">[</span><span class="n">subfeed_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np_val</span>
          <span class="n">feed_map</span><span class="p">[</span><span class="n">subfeed_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">subfeed_t</span><span class="p">,</span> <span class="n">subfeed_val</span><span class="p">)</span>

    <span class="c1"># Create a fetch handler to take care of the structure of fetches.</span>
    <span class="n">fetch_handler</span> <span class="o">=</span> <span class="n">_FetchHandler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="p">,</span> <span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict_string</span><span class="p">)</span>

    <span class="c1"># Run request and get response.</span>
    <span class="c1"># We need to keep the movers alive for the following _do_run().</span>
    <span class="c1"># These movers are no longer needed when _do_run() completes, and</span>
    <span class="c1"># are deleted when `movers` goes out of scope when this _run() ends.</span>
    <span class="c1"># TODO(yuanbyu, keveman): Revisit whether we should just treat feeding</span>
    <span class="c1"># of a handle from a different device as an error.</span>
    <span class="n">movers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_update_with_movers</span><span class="p">(</span><span class="n">feed_dict_string</span><span class="p">,</span> <span class="n">feed_map</span><span class="p">)</span>
    <span class="n">final_fetches</span> <span class="o">=</span> <span class="n">fetch_handler</span><span class="o">.</span><span class="n">fetches</span><span class="p">()</span>
    <span class="n">final_targets</span> <span class="o">=</span> <span class="n">fetch_handler</span><span class="o">.</span><span class="n">targets</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">final_fetches</span> <span class="ow">or</span> <span class="n">final_targets</span><span class="p">:</span>
      <span class="n">results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_run</span><span class="p">(</span><span class="n">handle</span><span class="p">,</span> <span class="n">final_targets</span><span class="p">,</span> <span class="n">final_fetches</span><span class="p">,</span>
                             <span class="n">feed_dict_string</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">return</span> <span class="n">fetch_handler</span><span class="o">.</span><span class="n">build_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">results</span><span class="p">)</span>

  <span class="c1"># Captures the name of a node in an error status.</span>
  <span class="n">_NODEDEF_NAME_RE</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\[\[Node: ([^ ]*?) =&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_do_run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">target_list</span><span class="p">,</span> <span class="n">fetch_list</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span>
              <span class="n">options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs a step based on the given fetches and feeds.</span>

<span class="sd">    Args:</span>
<span class="sd">      handle: a handle for partial_run. None if this is just a call to run().</span>
<span class="sd">      target_list: A list of byte arrays corresponding to names of tensors</span>
<span class="sd">        or operations to be run to, but not fetched.</span>
<span class="sd">      fetch_list: A list of byte arrays corresponding to names of tensors to</span>
<span class="sd">        be fetched and operations to be run.</span>
<span class="sd">      feed_dict: A dictionary that maps tensor names (as byte arrays) to</span>
<span class="sd">        numpy ndarrays.</span>
<span class="sd">      options: A (pointer to a) [`RunOptions`] protocol buffer, or None</span>
<span class="sd">      run_metadata: A (pointer to a) [`RunMetadata`] protocol buffer, or None</span>

<span class="sd">    Returns:</span>
<span class="sd">      A list of numpy ndarrays, corresponding to the elements of</span>
<span class="sd">      `fetch_list`.  If the ith element of `fetch_list` contains the</span>
<span class="sd">      name of an operation, the first Tensor output of that operation</span>
<span class="sd">      will be returned for that element.</span>

<span class="sd">    Raises:</span>
<span class="sd">      tf.errors.OpError: Or one of its subclasses on error.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">_run_fn</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span> <span class="n">fetch_list</span><span class="p">,</span> <span class="n">target_list</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span>
                <span class="n">run_metadata</span><span class="p">):</span>
      <span class="c1"># Ensure any changes to the graph are reflected in the runtime.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_extend_graph</span><span class="p">()</span>
      <span class="k">with</span> <span class="n">errors</span><span class="o">.</span><span class="n">raise_exception_on_not_ok_status</span><span class="p">()</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_Run</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span>
                                 <span class="n">feed_dict</span><span class="p">,</span> <span class="n">fetch_list</span><span class="p">,</span> <span class="n">target_list</span><span class="p">,</span>
                                 <span class="n">status</span><span class="p">,</span> <span class="n">run_metadata</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_prun_fn</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span> <span class="n">fetch_list</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">target_list</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;partial_run() requires empty target_list.&#39;</span><span class="p">)</span>
      <span class="k">with</span> <span class="n">errors</span><span class="o">.</span><span class="n">raise_exception_on_not_ok_status</span><span class="p">()</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_PRun</span><span class="p">(</span><span class="n">session</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span> <span class="n">fetch_list</span><span class="p">,</span>
                                  <span class="n">status</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">handle</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_call</span><span class="p">(</span><span class="n">_run_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_session</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span> <span class="n">fetch_list</span><span class="p">,</span>
                           <span class="n">target_list</span><span class="p">,</span> <span class="n">options</span><span class="p">,</span> <span class="n">run_metadata</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_do_call</span><span class="p">(</span><span class="n">_prun_fn</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_session</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span>
                           <span class="n">fetch_list</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_do_call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">errors</span><span class="o">.</span><span class="n">OpError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="n">message</span> <span class="o">=</span> <span class="n">compat</span><span class="o">.</span><span class="n">as_text</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>
      <span class="n">m</span> <span class="o">=</span> <span class="n">BaseSession</span><span class="o">.</span><span class="n">_NODEDEF_NAME_RE</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
      <span class="n">node_def</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="n">op</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="k">if</span> <span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">node_name</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
          <span class="n">op</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">get_operation_by_name</span><span class="p">(</span><span class="n">node_name</span><span class="p">)</span>
          <span class="n">node_def</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">node_def</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
          <span class="k">pass</span>
      <span class="k">raise</span> <span class="nb">type</span><span class="p">(</span><span class="n">e</span><span class="p">)(</span><span class="n">node_def</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">message</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_extend_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Ensure any changes to the graph are reflected in the runtime.</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_extend_lock</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">version</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_version</span><span class="p">:</span>
        <span class="c1"># pylint: disable=protected-access</span>
        <span class="n">graph_def</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_current_version</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_graph</span><span class="o">.</span><span class="n">_as_graph_def</span><span class="p">(</span>
            <span class="n">from_version</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_version</span><span class="p">,</span>
            <span class="n">add_shapes</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_add_shapes</span><span class="p">)</span>
        <span class="c1"># pylint: enable=protected-access</span>

        <span class="k">with</span> <span class="n">errors</span><span class="o">.</span><span class="n">raise_exception_on_not_ok_status</span><span class="p">()</span> <span class="k">as</span> <span class="n">status</span><span class="p">:</span>
          <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_ExtendGraph</span><span class="p">(</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">_session</span><span class="p">,</span> <span class="n">graph_def</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">(),</span> <span class="n">status</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_opened</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="c1"># The threshold to run garbage collection to delete dead tensors.</span>
  <span class="n">_DEAD_HANDLES_THRESHOLD</span> <span class="o">=</span> <span class="mi">10</span>

  <span class="k">def</span> <span class="nf">_register_dead_handle</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">handle</span><span class="p">):</span>
    <span class="c1"># Register a dead handle in the session. Delete the dead tensors when</span>
    <span class="c1"># the number of dead tensors exceeds certain threshold.</span>
    <span class="n">tensors_to_delete</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_delete_lock</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_dead_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dead_handles</span><span class="p">)</span> <span class="o">==</span> <span class="n">BaseSession</span><span class="o">.</span><span class="n">_DEAD_HANDLES_THRESHOLD</span><span class="p">:</span>
        <span class="n">tensors_to_delete</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dead_handles</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dead_handles</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Delete the dead tensors.</span>
    <span class="c1"># TODO(yuanbyu): For now we use a sequence of runs to minimize the graph</span>
    <span class="c1"># size and the overhead of graph construction/partitioning.</span>
    <span class="k">if</span> <span class="n">tensors_to_delete</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">tensor_handle</span> <span class="ow">in</span> <span class="n">tensors_to_delete</span><span class="p">:</span>
        <span class="n">feeds</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">fetches</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">holder</span><span class="p">,</span> <span class="n">deleter</span> <span class="o">=</span> <span class="n">session_ops</span><span class="o">.</span><span class="n">_get_handle_deleter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span>
                                                          <span class="n">tensor_handle</span><span class="p">)</span>
        <span class="n">feeds</span><span class="p">[</span><span class="n">holder</span><span class="p">]</span> <span class="o">=</span> <span class="n">tensor_handle</span>
        <span class="n">fetches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">deleter</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feeds</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_update_with_movers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">feed_dict</span><span class="p">,</span> <span class="n">feed_map</span><span class="p">):</span>
    <span class="c1"># If a tensor handle that is fed to a device incompatible placeholder,</span>
    <span class="c1"># we move the tensor to the right device, generate a new tensor handle,</span>
    <span class="c1"># and update `feed_dict` to use the new handle.</span>
    <span class="n">handle_movers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">feed_name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">feed_map</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="n">mover</span> <span class="o">=</span> <span class="n">session_ops</span><span class="o">.</span><span class="n">_get_handle_mover</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="o">*</span><span class="n">val</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">mover</span><span class="p">:</span>
        <span class="n">handle_movers</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">feed_name</span><span class="p">,</span> <span class="n">val</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">mover</span><span class="p">))</span>
    <span class="c1"># Transfer a tensor to the right device if needed.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">handle_movers</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">[]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">feeds</span> <span class="o">=</span> <span class="p">{}</span>
      <span class="n">fetches</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">handle</span><span class="p">,</span> <span class="n">mover</span> <span class="ow">in</span> <span class="n">handle_movers</span><span class="p">:</span>
        <span class="n">feeds</span><span class="p">[</span><span class="n">mover</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">handle</span>
        <span class="n">fetches</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mover</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
      <span class="n">handles</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">fetches</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feeds</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">handle_mover</span><span class="p">,</span> <span class="n">handle</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">handle_movers</span><span class="p">,</span> <span class="n">handles</span><span class="p">):</span>
        <span class="n">np_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">handle</span><span class="o">.</span><span class="n">handle</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">object</span><span class="p">)</span>
        <span class="n">feed_dict</span><span class="p">[</span><span class="n">handle_mover</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span> <span class="o">=</span> <span class="n">np_val</span>
      <span class="k">return</span> <span class="n">handles</span>


<span class="k">class</span> <span class="nc">Session</span><span class="p">(</span><span class="n">BaseSession</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A class for running TensorFlow operations.</span>

<span class="sd">  A `Session` object encapsulates the environment in which `Operation`</span>
<span class="sd">  objects are executed, and `Tensor` objects are evaluated. For</span>
<span class="sd">  example:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Build a graph.</span>
<span class="sd">  a = tf.constant(5.0)</span>
<span class="sd">  b = tf.constant(6.0)</span>
<span class="sd">  c = a * b</span>

<span class="sd">  # Launch the graph in a session.</span>
<span class="sd">  sess = tf.Session()</span>

<span class="sd">  # Evaluate the tensor `c`.</span>
<span class="sd">  print(sess.run(c))</span>
<span class="sd">  ```</span>

<span class="sd">  A session may own resources, such as</span>
<span class="sd">  [variables](../../api_docs/python/state_ops.md#Variable), [queues](../../api_docs/python/io_ops.md#QueueBase),</span>
<span class="sd">  and [readers](../../api_docs/python/io_ops.md#ReaderBase). It is important to release</span>
<span class="sd">  these resources when they are no longer required. To do this, either</span>
<span class="sd">  invoke the [`close()`](#Session.close) method on the session, or use</span>
<span class="sd">  the session as a context manager. The following two examples are</span>
<span class="sd">  equivalent:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Using the `close()` method.</span>
<span class="sd">  sess = tf.Session()</span>
<span class="sd">  sess.run(...)</span>
<span class="sd">  sess.close()</span>

<span class="sd">  # Using the context manager.</span>
<span class="sd">  with tf.Session() as sess:</span>
<span class="sd">    sess.run(...)</span>
<span class="sd">  ```</span>

<span class="sd">  The [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)</span>
<span class="sd">  protocol buffer exposes various configuration options for a</span>
<span class="sd">  session. For example, to create a session that uses soft constraints</span>
<span class="sd">  for device placement, and log the resulting placement decisions,</span>
<span class="sd">  create a session as follows:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Launch the graph in a session that allows soft device placement and</span>
<span class="sd">  # logs the placement decisions.</span>
<span class="sd">  sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,</span>
<span class="sd">                                          log_device_placement=True))</span>
<span class="sd">  ```</span>

<span class="sd">  @@__init__</span>
<span class="sd">  @@run</span>
<span class="sd">  @@close</span>

<span class="sd">  @@graph</span>

<span class="sd">  @@as_default</span>

<span class="sd">  @@reset</span>

<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a new TensorFlow session.</span>

<span class="sd">    If no `graph` argument is specified when constructing the session,</span>
<span class="sd">    the default graph will be launched in the session. If you are</span>
<span class="sd">    using more than one graph (created with `tf.Graph()` in the same</span>
<span class="sd">    process, you will have to use different sessions for each graph,</span>
<span class="sd">    but each graph can be used in multiple sessions. In this case, it</span>
<span class="sd">    is often clearer to pass the graph to be launched explicitly to</span>
<span class="sd">    the session constructor.</span>

<span class="sd">    Args:</span>
<span class="sd">      target: (Optional.) The execution engine to connect to.</span>
<span class="sd">        Defaults to using an in-process engine. See</span>
<span class="sd">        [Distributed Tensorflow](https://www.tensorflow.org/how_tos/distributed/index.html)</span>
<span class="sd">        for more examples.</span>
<span class="sd">      graph: (Optional.) The `Graph` to be launched (described above).</span>
<span class="sd">      config: (Optional.) A [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)</span>
<span class="sd">        protocol buffer with configuration options for the session.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Session</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
    <span class="c1"># NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph_context_manager</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_session_context_manager</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">__enter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph_context_manager</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph_context_manager</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Session context managers are not re-entrant. &#39;</span>
                         <span class="s1">&#39;Use `Session.as_default()` if you want to enter &#39;</span>
                         <span class="s1">&#39;a session multiple times.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_session_context_manager</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_default_session_context_manager</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph_context_manager</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_default_session_context_manager</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">__exit__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">exec_type</span><span class="p">,</span> <span class="n">exec_value</span><span class="p">,</span> <span class="n">exec_tb</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">exec_type</span> <span class="ow">is</span> <span class="n">errors</span><span class="o">.</span><span class="n">OpError</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">&#39;Session closing due to OpError: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">exec_value</span><span class="p">,))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_session_context_manager</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span>
        <span class="n">exec_type</span><span class="p">,</span> <span class="n">exec_value</span><span class="p">,</span> <span class="n">exec_tb</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph_context_manager</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="n">exec_type</span><span class="p">,</span> <span class="n">exec_value</span><span class="p">,</span> <span class="n">exec_tb</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_default_session_context_manager</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph_context_manager</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

  <span class="nd">@staticmethod</span>
  <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">containers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Resets resource containers on `target`, and close all connected sessions.</span>

<span class="sd">    A resource container is distributed across all workers in the</span>
<span class="sd">    same cluster as `target`.  When a resource container on `target`</span>
<span class="sd">    is reset, resources associated with that container will be cleared.</span>
<span class="sd">    In particular, all Variables in the container will become undefined:</span>
<span class="sd">    they lose their values and shapes.</span>

<span class="sd">    NOTE:</span>
<span class="sd">    (i) reset() is currently only implemented for distributed sessions.</span>
<span class="sd">    (ii) Any sessions on the master named by `target` will be closed.</span>

<span class="sd">    If no resource containers are provided, all containers are reset.</span>

<span class="sd">    Args:</span>
<span class="sd">      target: The execution engine to connect to.</span>
<span class="sd">      containers: A list of resource container name strings, or `None` if all of</span>
<span class="sd">        all the containers are to be reset.</span>
<span class="sd">      config: (Optional.) Protocol buffer with configuration options.</span>

<span class="sd">    Raises:</span>
<span class="sd">      tf.errors.OpError: Or one of its subclasses if an error occurs while</span>
<span class="sd">        resetting containers.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">target</span> <span class="o">=</span> <span class="n">compat</span><span class="o">.</span><span class="n">as_bytes</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">containers</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">containers</span> <span class="o">=</span> <span class="p">[</span><span class="n">compat</span><span class="o">.</span><span class="n">as_bytes</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">containers</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">containers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">tf_session</span><span class="o">.</span><span class="n">TF_Reset</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">containers</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">InteractiveSession</span><span class="p">(</span><span class="n">BaseSession</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;A TensorFlow `Session` for use in interactive contexts, such as a shell.</span>

<span class="sd">  The only difference with a regular `Session` is that an `InteractiveSession`</span>
<span class="sd">  installs itself as the default session on construction.</span>
<span class="sd">  The methods [`Tensor.eval()`](../../api_docs/python/framework.md#Tensor.eval)</span>
<span class="sd">  and [`Operation.run()`](../../api_docs/python/framework.md#Operation.run)</span>
<span class="sd">  will use that session to run ops.</span>

<span class="sd">  This is convenient in interactive shells and [IPython</span>
<span class="sd">  notebooks](http://ipython.org), as it avoids having to pass an explicit</span>
<span class="sd">  `Session` object to run ops.</span>

<span class="sd">  For example:</span>

<span class="sd">  ```python</span>
<span class="sd">  sess = tf.InteractiveSession()</span>
<span class="sd">  a = tf.constant(5.0)</span>
<span class="sd">  b = tf.constant(6.0)</span>
<span class="sd">  c = a * b</span>
<span class="sd">  # We can just use &#39;c.eval()&#39; without passing &#39;sess&#39;</span>
<span class="sd">  print(c.eval())</span>
<span class="sd">  sess.close()</span>
<span class="sd">  ```</span>

<span class="sd">  Note that a regular session installs itself as the default session when it</span>
<span class="sd">  is created in a `with` statement.  The common usage in non-interactive</span>
<span class="sd">  programs is to follow that pattern:</span>

<span class="sd">  ```python</span>
<span class="sd">  a = tf.constant(5.0)</span>
<span class="sd">  b = tf.constant(6.0)</span>
<span class="sd">  c = a * b</span>
<span class="sd">  with tf.Session():</span>
<span class="sd">    # We can also use &#39;c.eval()&#39; here.</span>
<span class="sd">    print(c.eval())</span>
<span class="sd">  ```</span>

<span class="sd">  @@__init__</span>
<span class="sd">  @@close</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">graph</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Creates a new interactive TensorFlow session.</span>

<span class="sd">    If no `graph` argument is specified when constructing the session,</span>
<span class="sd">    the default graph will be launched in the session. If you are</span>
<span class="sd">    using more than one graph (created with `tf.Graph()` in the same</span>
<span class="sd">    process, you will have to use different sessions for each graph,</span>
<span class="sd">    but each graph can be used in multiple sessions. In this case, it</span>
<span class="sd">    is often clearer to pass the graph to be launched explicitly to</span>
<span class="sd">    the session constructor.</span>

<span class="sd">    Args:</span>
<span class="sd">      target: (Optional.) The execution engine to connect to.</span>
<span class="sd">        Defaults to using an in-process engine.</span>
<span class="sd">      graph: (Optional.) The `Graph` to be launched (described above).</span>
<span class="sd">      config: (Optional) `ConfigProto` proto used to configure the session.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">config</span><span class="p">:</span>
      <span class="n">config</span> <span class="o">=</span> <span class="n">config_pb2</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">()</span>
    <span class="c1"># Interactive sessions always place pruned graphs.</span>
    <span class="n">config</span><span class="o">.</span><span class="n">graph_options</span><span class="o">.</span><span class="n">place_pruned_graph</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">InteractiveSession</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">graph</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_session</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_session</span><span class="o">.</span><span class="n">enforce_nesting</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_session</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_explicit_graph</span> <span class="o">=</span> <span class="n">graph</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_explicit_graph</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph</span><span class="o">.</span><span class="n">enforce_nesting</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Closes an `InteractiveSession`.&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">InteractiveSession</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_explicit_graph</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_default_graph</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_default_session</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2016, Blaine Rogers.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.5.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.9</a>
      
    </div>

    

    
  </body>
</html>